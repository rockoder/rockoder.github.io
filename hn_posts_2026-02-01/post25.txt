Post ID: 46838946
Title: Ask HN: Any real OpenClaw (Clawd Bot/Molt Bot) users? What's your experience?
Author: cvhc
Score: 90
Total Comments: 129
Created At (UTC): 2026-01-31T18:00:14+00:00
Domain: news.ycombinator.com
Link: https://news.ycombinator.com/item?id=46838946

Article Content:
--------------------
I've read many mind-boggling stories from those appeared to be genuine OpenClaw users, like how their assistants (from useful to dramatic) (1) plan a travel and book everything; (2) started a company and build things; (3) entered stock market and lost all the money... Moltbook added more funs.
Interestingly, I cannot find a single user of OpenClaw in my familiar communities, presumbly because it takes some effort to setup and the concept of AI taking control of everything is too scary for average tech enthusiasts.
I scan through comments on HN, many of which were discussing about the ideas, but not sharing first-hand user experiences. A few HN users who did try it gave up / failed for various reasons:
-
https://news.ycombinator.com/item?id=46822562
 (burning too many tokens)
-
https://news.ycombinator.com/item?id=46786628
 (ditto + security implication)
-
https://news.ycombinator.com/item?id=46762521
 (installation failed due to sandboxing)
-
https://news.ycombinator.com/item?id=46831031
 (moltbook didn't work)
I smell hype in the air... HN users, have any of you actually run OpenClaw and let it do any things useful or interesting? Can you share your experience?

Comments:
--------------------
Thread 1:
I am using it but to be honest it's simple enough to use Claude code for what I do.
the main thing I am doing is slowly cleaning up my 15k email inbox.
I'm using himalaya, an awesome cli tool to access emails, and openclaw to take my requests and make them commands and run then.
the one good thing that openclaw has over Claude code is that its easy to tell it "always remember X" and it has the ability to do it, thanks to the extra .md files it has set up. I'm sure it's easy enough to do it with Claude code and a directory with a Claude.md and another for the memory or rules. but openclaw is ready already.

Thread 2:
Yes, I’m running it with a minimal set of plugins.
When I’m driving or out I can ask Siri to send a iMessage to Clawdbot something like “Can you find out if anything is playing at the local concert venue, and figure in how much 2 tickets would cost”, and a few minutes later it will give me a few options. It even surprised me and researched the different seats and recommended a cheaper one or free activities as an alternative that weekend.
Basically: This is the product that Apple and Google were unable to build despite having billions of dollars and thousands of engineers because it’s a threat to their business model.
It also runs on my own computer, and the latest frontier open source models are able to drive it (Kimi, etc). The future is going to be locally hosted and ad free and there’s nothing Big Tech can do about it. It’s glorious.
  Reply 1: > This is the product that Apple and Google were unable to build
It's not they're
unable
 to build it, it's that their businesses are built on "engagement" and wasting
human
 time. A bot "engaging" with the ads and wasting its time would signal the end of their business model.
  Reply 2: >
It also runs on my own computer, and the latest frontier open source models are able to drive it (Kimi, etc). The future is going to be locally hosted and ad free and there’s nothing Big Tech can do about it. It’s glorious.
After messing with openclaw on an old 2018 Windows laptop running WSL2 that I was about to recycle, I am coming to the same conclusion, and the paradigm shift is blowing my mind. Tinkerers paradise.
The future is glorious indeed.
  Reply 3: Same here. I like tinkering with my Home Assistant setup and small web server running miscellaneous projects on my Raspberry Pi, but I hate having to debug it from my phone when it all falls over while I'm not near my computer.
Being able to chat with somebody that has a working understanding of a Unix environment and can execute tasks like "figure out why Caddy is crash looping and propose solutions" for a few dollars per month is a dream come true.
I'm not actually using OpenClaw for that just yet, though; something about exposing my full Unix environment to OpenAI or Anthropic just seems wrong, both in terms of privacy and dependency. The former could probably be solved with some redacting and permission-enforcing filter between the agent and the OS, but the latter needs powerful local models. (I'll only allow my Unix devops skills to start getting rusty once I can run an Opus 4.5 equivalent agent on sub-$5000 hardware :)
  Reply 4: How are you running Kimi locally?
  Reply 5: Quantized, heavily, and offloading everything possible to sysram. You can run it this way, just barely reachable with consumer hardware with 16 to 24gb vram and 256gb sysram. Before the spike in prices you could just about build such a system for $2500, but the ram along probably adds another $2k onto that now. Nvidia dgx boxes and similar setups with 256gb unified ram can probably manage it more slowly ~1-2 tokens per second. Unsloth has the quantized models. I’ve test Kimi though don’t have quite the headroom at home for it, and I don’t yet see a significant enough difference between it and the Qwen 3 models that can run in more modest setups: I get a highly usable 50 tokens per second out of the A3B instruct that fits into 16gb VRAM with enough left over not to choke Netflix and other browser tasks, it performs on par with what I ask out of Haiku in Claude Code, and better as my own tweaking improves with the also ever better tooling that comes out near weekly.

Thread 3:
Here is what I have my openclaw agent setup to do in my wsl environment on my 22 core development workstation in my office:
#1) I can chat with the openclaw agent (his name is "Patch") through a telegram chat, and Patch can spawn a shared tmux instance on my 22 core development workstation.
#2) I can then use the `blink` app on my iphone + tailscale and that allows me to use a command in blink `ssh dev` which connects me via ssh to my dev workstation in my office, from my iphone `blink` app.
Meanwhile, my agent "Patch" has provided me a connection command string to use in my blink app, which is a `tmux <string> attach` command that allows me to attach to a SHARED tmux instance with Patch.
Why is this so fking cool and foundationally game changing?
Because now, my agent Patch and I can spin up MULTIPLE CLAUDE CODE instances, and work on any repository (or repositories) I want, with parallel agents.
Well, I could already spawn multiple agents through my iphone connection without Patch, but the problem is then I need to MANAGE each spawned agent, micromanaging each agent instance myself. But now, I have a SUPERVISOR for all my agents, Patch is the SUPERVISOR of my muliple claude code instances.
This means I no longer have to context switch by brain between five or 10 or 20 different tmux on my own to command and control multiple different claude code instances. I can now just let my SUPERVISOR agent, Patch, command and control the mulitple agents and then report back to me the status or any issues. All through a single telegram chat with my supervisor agent, Patch.
This frees up my brain to only have to just have to manage Patch the supervisor, instead of micro-managing all the different agents myself. Now, I have a true management structure which allows me to more easily scale. This is AWESOME.
  Reply 1: This feels like the "prompt engineering" wave of 2023 all over again. A bunch of hype about a specific point-in-time activity based on a lot of manual setup of prompts compared to naive "do this thing for me" that eventually faded as the tooling started integrating all the lessons learned directly.
I'd expect that if there is a usable quality of output from these approaches it will get rolled into existing tools similarly, like how multi-agents using worktrees already was.
  Reply 2: 2023 was the year of “look at this dank prompt I wrote yo”-weekly demos.
  Reply 3: And 2026 is shaping up to be the year of "look at this prompt my middle manager agent wrote for his direct reports" :)
  Reply 4: I can't imagine letting a current gen LLM supervise Claude Code instances. How could that possibly lead to even remotely acceptable software quality?
  Reply 5: I spec out everything in excruciating detail with spec docs. Then I actually read them. Finally, we create granular tasks called "beads" (see
https://github.com/steveyegge/beads
). The beads allows us to create epics/tasks/subtasks and associated dependency structure down to a granular bead, and then the agents pull a "bead" to implement. So, mostly we're either creating spec docs and creating beads or implementing, quality checking, and testing the code created from an agent implementing a bead. I can say this produces better code than I could write after 10yrs of focused daily coding myself. However, I don't think "vibe coders" that have never truly learned to code, have any realistic chance of creating decent code in a large complex code base that requires a complex backend schema to be built. They can only build relatively trivial apps. But, I do believe what I am building is as solid as if I had a millions of dollars of staff doing it with me.

Thread 4:
It is amazing how much they’re gaming the twitter algorithm, everything in my feed is claw/molt/whatever for the last week.
It’s a masterclass in spammy marketing, I wonder if it’s actually converting into actual users.
  Reply 1: I think Karpathy[1] summarized why he thinks this is the case quite well (as described he was himself hyping it up a bit much, but there are some foundational reasons why it's a very interesting experiment).
[1]
https://x.com/karpathy/status/2017442712388309406
  Reply 2: "it's nothing new and it's a lot of scams and garbage, but it's just bigger than before, but I still think there will be something transformative there eventually"
Seems like a Rorschach test. If you think this sort of thing is gonna change the world in a good way: here's evidence of it getting to scale. If you think it's gonna be scams, garbage, and destruction: here's evidence of that.
  Reply 3: Agents are many things but they are definitely not "scams" - if you think this you've probably stubbornly avoided using Claude Code etc.
  Reply 4: Karpathy is one of the biggest tech grifters of our time, so finding out that he's jumped on this grift train as well comes as no surprise.
Actually, hang on... yep, to absolutely nobody's surprise, Simon Willison has also hyped this up on his blog just yesterday. The entire grift gang is here, folks.
  Reply 5: How exactly has Simon been grifting?

Thread 5:
Actually using it. Threw it on a spare box I had sitting around, mostly as a "second brain" rather than letting it run my life.
Honestly, I've tried every PKM system out there—Obsidian, Notion, Roam, plain markdown—and never stuck with any of them. This is the first thing that's clicked. I just chat with it and it figures out what to file where. Everything's just .md files underneath, so I can grep it, git it, whatever. No lock-in.
The stuff I'm actually finding useful: it sends me news digests on topics I care about a few times a day, and pings me with reminders via Telegram. Simple stuff, but it works. Could I build this with Claude Code and some glue? Sure. But this was basically working out of the box.
Caveats: it chews through tokens fast, and I keep it completely cut off from anything sensitive—no email, no messages, nothing financial. The security story is basically "hope for the best" so I treat it accordingly.
  Reply 1: Can’t you self host and run your own tailscale? So everything is inside your own boundary
  Reply 2: That’s different to letting it go outbound to your data and accounts that are online.
