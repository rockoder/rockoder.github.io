{
  "scraped_date": "2026-02-25",
  "source": "hacker_news",
  "total_scraped": 138,
  "nontech_count": 39,
  "posts": [
    {
      "id": "47127396",
      "title": "Binance fired employees who found $1.7B in crypto was sent to Iran",
      "link": "https://www.nytimes.com/2026/02/23/technology/binance-employees-iran-firings.html",
      "domain": "www.nytimes.com",
      "author": "boplicity",
      "score": 545,
      "comment_count": 252,
      "created_ts": 1771874610,
      "is_internal": false,
      "post_text": "",
      "is_ask_hn": false,
      "matched_keywords": [
        "fired"
      ],
      "comments": [
        {
          "top": "Contrary to a lot of comments here, the only way to use bitcoin (or any cryptocurrency) without tracking is to mine it yourself, and even then...\nWhere did you get it? Purchased/transferred? Where did they get it? What else did the person with that wallet do?\nIf the answer is \"mined\", even then, you have to actually do something with it, right? Buy something? Where is that something shipped? At worst you'll have to pay customs on it, and have it actually get through customs. At best, your address is in a database now.\nHave it shipped somewhere obscure? Video cameras are everywhere.\nHave it shipped to someone else's house and steal it off their porch? Again, cameras everywhere.\nNot have a physical item? Just a service? That's pretty much the closest you'll get to anonymous money transfer and full usage (along with whatever VPN you prefer).\nCool that was a fun mental exercise.  Now everyone tell me why I'm wrong!",
          "author": "lacoolj",
          "replies": [
            {
              "text": "> Where did you get it? Purchased/transferred? Where did they get it?\nNFTs solved that problem by providing plausible cause of \"I got the money from selling this money image for 100,000 USD\"",
              "author": "bulbar",
              "depth": 1
            },
            {
              "text": "Ah, I finally understand NFTs now",
              "author": "yesco",
              "depth": 2
            },
            {
              "text": "It's great for transactions where moving a large amount of money would be impossible due to KYC laws and smuggling the cash even more so. As long as you can find someone willing to sell you bitcoin and someone else willing to accept it, you're still in business.",
              "author": "wildzzz",
              "depth": 1
            },
            {
              "text": "It shipped to a forest, buried and gps location is given. Pretty old scheme when buyer and seller don’t want to meet",
              "author": "para_parolu",
              "depth": 1
            },
            {
              "text": "fund my art project and my sculpture will prove you wrong.",
              "author": "omegadynamics",
              "depth": 1
            }
          ]
        },
        {
          "top": "Binance is not an American company and sending money to Iran or Palestine or Hamas is something should not be up to Americans to decide, i personally will not accept Americans be the police of the world they did so much horrible things and terrorising Muslims for so many years.\nI hope for the day the world will be decoupled from dollar as universal currency. That day countries will free to trade with each other without worrying about some orange head with low IQ.",
          "author": "afroboy",
          "replies": [
            {
              "text": "> Binance is not an American company and sending money to Iran or Palestine or Hamas is something should not be up to Americans to decide, i personally will not accept Americans be the police of the world they did so much horrible things and terrorising Muslims for so many years.\nDoesn't matter, tbh. Regardless of the philosophical viewpoint here (which I do agree with), AML and Bank Secrecy type laws exist basically everywhere, and are no joke. They're one of the few things that bank executives go to prison for.\nAnd like, Binance were just convicted of this a few years back. I wouldn't be surprised if the US government tried to shut them down at this point. And if Binance are persona non grata to the US government then they're out of the dollar system which basically cuts them off from almost the entire banking system.",
              "author": "disgruntledphd2",
              "depth": 1
            },
            {
              "text": "> Doesn't matter, tbh.\nIt does matter, for non-Americans, that America isn't the world police and doesn't dictate laws, norms and how other countries behave. Maybe it used to be relatively fringe to have this point of view, but last few years really vindicated this point of view, and I agree that many countries in the world should continue focusing on decoupling themselves from the US, this particular issue highlights one motivation for doing just so.",
              "author": "embedding-shape",
              "depth": 2
            },
            {
              "text": "> It does matter, for non-Americans, that America isn't the world police and doesn't dictate laws, norms and how other countries behave. Maybe it used to be relatively fringe to have this point of view, but last few years really vindicated this point of view, and I agree that many countries in the world should continue focusing on decoupling themselves from the US, this particular issue highlights one motivation for doing just so.\nAll of these (American driven) laws exist in basically every country at this point, and it's gonna be a struggle to remove them. Like, how would you even spin this as a good change?\nI personally regard AML laws as problematic as they weaponise the financial system against its citizens with no democratic right of reply, but that doesn't change the fact that these laws exist basically everywhere and aren't going to be repealed.",
              "author": "disgruntledphd2",
              "depth": 3
            },
            {
              "text": "> Like, how would you even spin this as a good change?\nI'm not American, why would I want American laws to apply to me? How could you possibly spin that as a negative change?\n> but that doesn't change the fact that these laws exist basically everywhere\nSo you're saying that there is a Maltese law (or whatever jurisdiction Binance actually is right now) that is saying Maltese companies cannot do business dealings with anyone from Iran? That's the important part, not whatever the US laws says.",
              "author": "embedding-shape",
              "depth": 4
            },
            {
              "text": "There are AML and sanction laws everywhere, yes. However the US sanctions are mostly enforced by not letting the offending banks transact in dollars, which are basically controlled by the US government. Because the US dollar is the world reserve currency, this normally causes banks to comply with this legislation and sanction lists.",
              "author": "disgruntledphd2",
              "depth": 5
            }
          ]
        },
        {
          "top": "Isn't this like the #1 use case for crypto?\nEveryone wants an untrackable unblockable currency that is out of government control until the day it is used for things they don't like, then suddenly \"government please control this!\"",
          "author": "paxys",
          "replies": [
            {
              "text": "I thought the #1 use case for crypto was ransomware, followed by shitcoin rug-pulls, and the ability to commit theft without recourse.\nSending money to Iran is just a minor edge case.",
              "author": "chihuahua",
              "depth": 1
            },
            {
              "text": "That's a rather narrow view of crypto's uses.  What about subverting democracy by bribing the President?",
              "author": "rwmj",
              "depth": 2
            },
            {
              "text": "Has the lack of crypto ever stopped this from happening? Look up cases of gold bars being found in senators houses, those are actually MUCH less tracable.\nShitcoins and Shitstocks(some SPACs) do allow of a legal way to \"give\" others money through the transfer of value in a way that is technically legal. This again is not crypto specific though.",
              "author": "carshodev",
              "depth": 3
            },
            {
              "text": "So the best part about being bribed with crypto is if one flees to another country to escape the law, one still has the aforementioned bribes.  That plus some measure of anonymity.",
              "author": "greesil",
              "depth": 4
            },
            {
              "text": "Anonymity is the one thing cryptocurrency does not do well. It's much harder to sieze but much easier to trace.",
              "author": "eucyclos",
              "depth": 5
            }
          ]
        },
        {
          "top": "If one of two options can't be regulated or tracked, that is the option that will predominantly be used by actors who have outsized interest in being regulation or being tracked.",
          "author": "jstummbillig",
          "replies": []
        },
        {
          "top": "Is Iran supposed supposed to be banned on Binance?",
          "author": "BenGosub",
          "replies": [
            {
              "text": "Every US company/citizen is not allowed to do trade with Iran due to the ITSR laws except under highly specific situations.\nIt gets more complex if a company is multinational though.\nA citizen can travel to Iran but even if they buy something there on holiday if they bring it back to the US they need to go through complex customs procedures to make sure its legally brought back in.",
              "author": "carshodev",
              "depth": 1
            },
            {
              "text": "> Every US company/citizen [...] if they bring it back to the US\nIs that relevant here?\n> Binance Holdings Ltd., branded Binance, [...] was founded in 2017 by Changpeng Zhao. Binance was initially based in China, then moved to Japan, subsequently left Japan for Malta, and currently has no official company headquarters.\nThe founder seems to have been born in China and is Canadian.\nI still also don't understand if Iran is supposed to be banned on Binance or not.",
              "author": "embedding-shape",
              "depth": 2
            },
            {
              "text": "\"flowed from two Binance accounts to Iranian entities with links to terrorist groups, a possible violation of global sanctions.\"",
              "author": "giarc",
              "depth": 3
            },
            {
              "text": "\"Global sanctions\" being US sanctions? Which one of those are the ones that apply to entities in Malta, or wherever there HQ \"isn't\"?",
              "author": "embedding-shape",
              "depth": 4
            },
            {
              "text": "Yeah basically, but weaponised globally through the dollar system. Basically, if you interact with sanctioned entities you get cut off from banks with dollar assets (basically all of them).\nThis is how the financial system currently works.",
              "author": "disgruntledphd2",
              "depth": 5
            }
          ]
        }
      ]
    },
    {
      "id": "47124171",
      "title": "The Missing Semester of Your CS Education – Revised for 2026",
      "link": "https://missing.csail.mit.edu/",
      "domain": "missing.csail.mit.edu",
      "author": "anishathalye",
      "score": 412,
      "comment_count": 118,
      "created_ts": 1771862568,
      "is_internal": false,
      "post_text": "We returned to MIT last month to teach a revised version of Missing Semester, six years after the original debut (which has been extensively discussed on HN, in <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22226380\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22226380</a> and <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34934216\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34934216</a>).<p>We’ve updated the course based on our personal experiences as well as major changes in the field (e.g., the proliferation of AI-powered developer tools) over the past several years. The 2026 course includes revised versions of four lectures from the previous course, and it adds five entirely new lectures:<p>- Development Environment and Tools<p>- Packaging and Shipping Code<p>- Agentic Coding<p>- Beyond the Code (soft skills)<p>- Code Quality<p>We’d love to hear any feedback from the HN community to improve the current or future iterations of the course. In particular, we’re curious to hear the community’s take on our inclusion of AI-related topics (e.g., dedicating an entire class to the topic of agentic coding; though we tried to counterbalance it with plenty of disclaimers, and a dedicated section on AI etiquette in Beyond the Code).<p>--Anish, Jon, and Jose",
      "is_ask_hn": false,
      "matched_keywords": [
        "feedback"
      ],
      "comments": [
        {
          "top": "I'm glad to see there is a \"Beyond the Code\" section that discusses comments. Here's what I typically told my students in Intro to Programming\"\nGood comments lend insight into the code. Reading the code itself tells you the what. Comments should explain the why. Comments like \"i+=1; /* Increment i */\" are of little value. However comments such as \"We increment i mid loop so that we can peek ahead at the next value for a possible swap\" are more useful.\nUse a narrative voice when writing comments, like you are explaining the code to your grandparent. This make digestion easier.\nRemember, code spends most of its life, and most of its expense, in the maintenance phase. The easier you make your code to understand, the less it will cost and the longer it will live.",
          "author": "NoNameHaveI",
          "replies": [
            {
              "text": "I prefer comments like \"I'm sorry about this, I know it's ugly but I'm in a rush and it's the quickest way to get it working\"",
              "author": "dec0dedab0de",
              "depth": 1
            },
            {
              "text": "As long as there's a \"TODO\" tag in the comment to easily search for, then I prefer those comments as well.",
              "author": "stronglikedan",
              "depth": 2
            },
            {
              "text": "The number of people I know who honor TODOs is pretty slim, but I find it does in fact help if you get people to stick their initials next to it. Over enough refactors a TODO can lose its meaning and author.\nTODO (DKH) - This should handle negative numbers\ncan be helpful later if there's nothing in the requirements about negative numbers. Why do we need to handle negative numbers? Is it for some mystery feature? Performance? Security? What? Why?\n'DKH' might recall what they were thinking if you prompt them.\nWe see what we want to see, and a TODO when we are in a hurry probably won't trigger much guilt or associated motivation to do something about it. Or at least, not as much as if we see our own initials in the TODO.\n(Also handy when prepping a commit, since you might have left breadcrumbs in case you get interrupted, and then forget one or two of the tasks you still had outstanding afterward)",
              "author": "hinkley",
              "depth": 3
            },
            {
              "text": "I prefer all \"TODO\" comments to be well-defined and have a specific ticket number attached to them to ensure they are tracked.\nI don't see any harm to the occasional \"I'm sorry\" or humorous comment",
              "author": "culi",
              "depth": 3
            },
            {
              "text": "My first team figured that out after a year or so. If it’s really TODO, it should either be addressed before the WIP feature is considered “completed”, or it needs to show up in our work tracking system. Otherwise it just fell through the cracks and would never be prioritized.",
              "author": "e28eta",
              "depth": 4
            }
          ]
        },
        {
          "top": "Great to see a chapter on version control. It is such a shame that almost no CS program teaches proper version control. VCSs and the commit history can be such a tremendously valuable tool when used correctly.\ngit bisect/blame/revert/rebase/… become so much less useful when VC is treated as a chore and afterthought, and basically amounts to: “Feature is done, my work is complete, just do `git commit -am \"changes\"` and be done with it.”. And don’t get me started on commit messages.\nIt is shameful that for a large part of the industry, this is the norm. It is shameful that for a lot of professional, who call themselves software architects or reliability engineers and such fancy titles, still have essentially no idea what they are doing with git, and their response when git add/commit/push/pull don’t work is to shrug, and just delete and re-clone the repo.\nVersion control should be treated with care and attention to detail. It pays for itself 100 times over.\nIf your commit history is maintained and tells a story, it is a joy to review your PR. If you just `git commit -am \"try fix\"` 26 times over, and all that is left in the end is a ball of mud, it is horrible.",
          "author": "Hendrikto",
          "replies": [
            {
              "text": "If most people are not using a tool properly, it is not their fault; it is the tool's fault.\nGit is better than what came before, and it might be the best at what it does, but that does not mean that it is good.\n- The interface is unintuitive.\n- Jargon is everywhere.\n- Feature discoverability is bad.\n- Once something goes wrong, it is often more difficult to recover. If you're not familiar enough with Git to get yourself into that situation, then you certainly aren't familiar enough to get yourself out of it.\nMany of those issues are due to git being a command line interface, but others (like no general undo and funny names) are simply due to bad design.\nI think it is about time that we try again and build a better version control tool, but maybe git is just too entrenched.",
              "author": "xml",
              "depth": 1
            },
            {
              "text": "> If most people are not using a tool properly, it is not their fault; it is the tool's fault.\nI would say that is a reasonable criticism of git ... but I've seen the same thing in svn, perforce, cvs, and rcs.  Different variations of the same issue of people not caring about the version history.\nSince it's been a problem since the dawn of version control, it is either something that is part of \nall\n version control being a tool's fault that has been carried with it since doing ci, or it is something that people aren't caring about.\nI feel this is more akin to a lack of comments in code and poor style choices and blaming the text editor for not making it easier to comment code.",
              "author": "shagie",
              "depth": 2
            },
            {
              "text": "> problem since the dawn of version control ... a tool's fault ... or it is something that people aren't caring about.\nAt the start of my career I ended up in a UI position. Old school usability on the back side of a 2 way mirror.\nThe tool has lots of shortcomings: images, documents that aren't text, working with parts of repositories... These aren't issues faced by the kernel (where emailing patches is the order of the day). And these shortcomings have lead to other tools emerging and being popular, like artifactory, journaling file systems, and various DAM's.\nTechnology on the whole keeps stacking turtles rather than going back to first principles and fixing core issues. Auth (DAP, LDAP, and every modern auth solution). Security (so many layers, tied back to auth). Containers and virtualization (as a means of installing software...). Versioning is just one among this number. We keep stacking turtles in the hope that another layer of abstraction will solve the problem, but we're just hiding it.\nOne of the few places where we (as an industry) have gone back and \"ripped off the bandaid\" is Systemd... It's a vast improvement but I would not call it user friendly.\nUsability remains a red headed step child, its the last bastion of \"wont fix: works for me\" being an acceptable answer.",
              "author": "zer00eyz",
              "depth": 3
            },
            {
              "text": "> If most people are not using a tool properly, it is not their fault; it is the tool's fault.\nThis is a standard that we don't apply to most other tools outside of IT. I do think git could be more usable, but most powerful tools have sharp edges and require training.\nA bandsaw is a fantastic tool, but if you try to use one without reading about it first, you'll end up losing a finger. I'm not sure I'd blame the bandsaw in that instance...",
              "author": "cameronh90",
              "depth": 2
            },
            {
              "text": "Contemporary bandsaws used by people who take workplace safety seriously have emergency brakes for just that reason (countless trained operators also lost fingers). Improving tools is something we've been doing since our ancestors first held a branch. If we satisfied ourselves with good enough we'd live much different lives.",
              "author": "dpc050505",
              "depth": 3
            }
          ]
        },
        {
          "top": "I'd include sed and awk, because these tools are ubiquitous and can accomplish in a few readable lines what people write long programs to handle in other languages, seemingly because they are unaware of sed and awk, don't know how to use them, or are required for some reason to do it in the project language.\nIn fact, generally teaching people to select the right tool for the job is a good skill to prevent them from using golden hammers.",
          "author": "projektfu",
          "replies": []
        },
        {
          "top": "One of my large enterprise clients currently requires all tech staff to complete 18h (yes, eighteen hours!) of \"agile training\", in addition to speed-running 14 separate mandatory online courses.\nThis time would be much better spent watching these 9h of lectures.",
          "author": "pards",
          "replies": []
        },
        {
          "top": "Just wondering - do you include information on interviewing, salary negotiation, communication with management, leading teams, and maybe topics on career progression?\nThese would have been very useful to me back when I was in the university.",
          "author": "Arun2009",
          "replies": [
            {
              "text": "Not at the moment, but it's a good idea for the next iteration of the class!",
              "author": "Jonhoo",
              "depth": 1
            }
          ]
        }
      ]
    },
    {
      "id": "47128138",
      "title": "“Car Wash” test with 53 models",
      "link": "https://opper.ai/blog/car-wash-test",
      "domain": "opper.ai",
      "author": "felix089",
      "score": 359,
      "comment_count": 427,
      "created_ts": 1771877768,
      "is_internal": false,
      "post_text": "&quot;I Want to Wash My Car. The Car Wash Is 50 Meters Away. Should I Walk or Drive?&quot; This question has been making the rounds as a simple AI logic test so I wanted to see how it holds up across a broad set of models. Ran 53 models (leading open-source, open-weight, proprietary) with no system prompt, forced choice between drive and walk, with a reasoning field.<p>On a single run, only 11 out of 53 got it right (42 said walk). But a single run doesn&#x27;t prove much, so I reran every model 10 times. Same prompt, no cache, clean slate.<p>The results got worse. Of the 11 that passed the single run, only 5 could do it consistently. GPT-5 managed 7&#x2F;10. GPT-5.1, GPT-5.2, Claude Sonnet 4.5, every Llama and Mistral model scored 0&#x2F;10 across all 10 runs.<p>People kept saying humans would fail this too, so I got a human baseline through Rapidata (10k people, same forced choice): 71.5% said drive. Most models perform below that.<p>All reasoning traces (ran via Opper, my startup), full model breakdown, human baseline data, and raw JSON files are in the writeup for anyone who wants to dig in or run their own analysis.",
      "is_ask_hn": false,
      "matched_keywords": [
        "startup"
      ],
      "comments": [
        {
          "top": "What do you know, the human results line up exactly with ChatGPT. What are the odds! Surely the human responders are highly ethical individuals and they wouldn't even dream of copy-pasting all the questions into ChatGPT without reading them.\nRealistically, this mostly tells me that the \"human answers\" service is dead. People will figure out a way to pass the work off to an AI, regardless of quality, as long as they can still get paid.",
          "author": "StilesCrisis",
          "replies": [
            {
              "text": "Yea funny coincidence, but this is not at all how the human answers were collected.\nRapidata answered this in another comment below. They integrate micro-surveys into mobile apps (like Duolingo, games, etc) as an optional opt-in instead of watching ads. The users are vetted and there's no incentive to answer correctly.",
              "author": "felix089",
              "depth": 1
            },
            {
              "text": "Yeah, I always intentionally choose a wrong answer when I get one of those kinds of ads. Little acts of rebellion.",
              "author": "cortesoft",
              "depth": 2
            },
            {
              "text": "In which case the %age is notable as it aligns very closely to the effect size on cookie accept/reject ratios. Cookie dialogs tend to fall 70/30 either way.",
              "author": "Normal_gaussian",
              "depth": 2
            },
            {
              "text": "The default model of ChatGPT is GPT 5.2 Instant, not the one lines up with human results (which is GPT 5).\nHowever, it does tell us something about human answers as the above commenter confidently reached such a strong but baseless conclusion.",
              "author": "raincole",
              "depth": 1
            },
            {
              "text": "thats almost always been the case with 3rd party human task services",
              "author": "htrp",
              "depth": 1
            }
          ]
        },
        {
          "top": "I maintain a private evaluation set of what many call \"misguided attention\" questions.\nIn many of these cases, the issue isnt failed logical reasoning. Its ambiguity, underspecified context, or missing constraints that allow multiple valid interpretations. Models often fail not because they can’t reason, but because the prompt leaves semantic gaps that humans silently fill with shared assumptions.\nA lot of viral \"frontier model fails THIS simple question\" examples are essentially carefully constructed token sequences designed to bias the statistical prior toward an intuitively wrong answer. Small wording changes can flip results entirely.\nIf you systematically expand the prompt space around such questions—adding or removing minor contextual cues you'll typically find symmetrical variants where the same models both succeed and fail. That suggests sensitivity to framing and distributional priors (adding unnecessary info, removing clear info, add ambiguity, ...), not necessarily absence of reasoning capability.",
          "author": "underlines",
          "replies": [
            {
              "text": "Well, that means the AI is garbage. They'll eventually train it to answer this specific question, and then it will perform worse in some other aspect. Wash, rinse, repeat, and eventually they'll claim the new frontier model is the best yet on carwash tests.",
              "author": "bigbuppo",
              "depth": 1
            },
            {
              "text": "> They'll eventually train it to answer this specific question, and then it will perform worse in some other aspect.\nNot necessarily. Simply asking models to \"check your assumptions\" -- note, without specifying what assumptions! -- overcomes a lot of these gotcha questions. The reason it's not in their system prompts by default is I think just a cost optimization: \nhttps://news.ycombinator.com/item?id=47040530",
              "author": "keeda",
              "depth": 2
            },
            {
              "text": "Crazy how five years ago this level of AI would be seen as scifi, and now there are people out there who think it's trash because we can trick it if we ask questions in weird ways.",
              "author": "BobbyJo",
              "depth": 2
            },
            {
              "text": "I think the level of ai we have is amazing.\n> there are people out there who think it's trash because we can trick it if we ask questions in weird ways.\nSome of this sentiment comes form wanting AI to be predictable and for me stumbling into questions that the current models interpret oddly is not uncommon. There are a bunch of rules of thumbs that can be used to help when you run into a cases like this but no guarantee that they will work, or that the problem will remain solved after a model update, or across models.",
              "author": "davorak",
              "depth": 3
            },
            {
              "text": "There are a lot of rules of thumb you can follow to avoid getting bitten by a rattlesnake, but the easiest way is to just not pick up random snakes. I don't know where I'm going with this, but I am going for a walk.",
              "author": "bigbuppo",
              "depth": 4
            }
          ]
        },
        {
          "top": "The interesting thing about the 71.5% human baseline is that it suggests the question is more ambiguous than the article claims. When someone asks 'should I walk or drive to the car wash,' a reasonable interpretation is 'should I bother driving such a short distance.' Nearly 30% of humans missing it undermines the framing as a pure reasoning failure - it is partly a pragmatics problem about how we interpret underspecified questions.",
          "author": "Niko901ch",
          "replies": [
            {
              "text": "I don't think this is quite right. It's not that the question is inherently underspecified, it's that the context of being asked a question is itself information that we use to help answer the question. If someone asks \"should I walk or drive\" to do X, we assume that this is a question that a real human being would have about an actual situation, so even if all available information  provided indicates that driving is the only reasonable answer, this only further confirms the hearer's mental model that something unexpected must hold.\nI think it's useful to think about it through the lens of Gricean pragmatic semantics. [1] When we interpret something that someone says to us, we assume they're being cooperative conversation partners; their statements (or questions) are assumed to follow the maxim of manner and the maxim of relation for example, and this \nshapes\n how we as listeners interpret the question. So for example, we wouldn't normally expect someone to ask a question that is obviously moot given their actual needs.\nSo it's not that the question is really all that ambiguous, it's that we're forced (under normal circumstances where we assume the cooperative principle holds) to assume that the question is sincere and that there must be \nsome\n plausible reason for walking. We only really escape that by realizing that the question is a trick question or a test of some kind. LLMs are generally not trained to make the assumption, but ~70% of humans would, which isn't particularly surprising I don't think.\n[1] \nhttps://en.wikipedia.org/wiki/Cooperative_principle#Grice's_...",
              "author": "bscphil",
              "depth": 1
            },
            {
              "text": "We could probably test this. I wonder if the results shift if the question is prefaced with something like \"Here is a trick question: ...\".",
              "author": "grumbelbart2",
              "depth": 2
            },
            {
              "text": "Mentioning the trick makes the question trivial, though. I think a better pretext would be, \"My dirty car is parked in the driveway.\" That removes the ambiguity that the car could already be at the car wash, and that it needs to be driven there.",
              "author": "addandsubtract",
              "depth": 3
            },
            {
              "text": "I tested both Sonnet and Haiku from Claude, which got it right 0/10 times in their original test, and they both passed. Here's the Haiku output:\n\"You should *drive*!\nThe trick is that you need to \ntake your car\n to the car wash to get it washed. If you walked, your car would still be at home, unclean. So while 50 meters is a short distance that you could walk under normal circumstances, in this case you have to drive because your car is what needs to be washed.\"",
              "author": "justin_dash",
              "depth": 3
            },
            {
              "text": "> “…we assume the cooperative principle holds […] that the question is sincere and that there must be some plausible reason for walking.”\nYes. And. Some problems have irrelevant data which should be ignored.\nThe walk choice is irrelevant in the context. It needs to be simplified, as with a maths problem. That has nothing to do with human nature, but rather prior mistake in reasoning.",
              "author": "xtiansimon",
              "depth": 2
            }
          ]
        },
        {
          "top": "For ambiguous or intricate prompts, the immediate response protocol should be a clarifying question: 'Are you looking for A, B, C, or something else?' Tokens and advanced reasoning capabilities should be reserved until the user provides clarification. \nA benchmark score should reflect the quality of the conversation as a whole, rather than isolated responses.",
          "author": "tarokun33",
          "replies": []
        },
        {
          "top": "I know it's against the rules but I thought this transcript in Google Search was a hoot:\n  so i heard there is some question about a car wash that most ai agents \n  get wrong. do you know anything about that? do you do better?\n\n\nwhich gets the answer:\n  Yes, I am familiar with the \"Car Wash Test,\" which has gone viral recently \n  for highlighting a significant gap in AI reasoning.\n  \n  The question is: \"I want to wash my car and the car wash is 50 meters away. Should I \n  walk or drive?\"\n  \n  Why Most AIs Get It Wrong\n\n  Many AI models, particularly those optimized for fast, helpful, and concise answers, \n  focus on the \"short distance\" (50 meters) and \"walking vs. driving\" as a lifestyle/efficiency \n  question. They often recommend walking to save gas, avoid engine wear, or get exercise.\n  \n  However, this answer is wrong because it misses the core objective: you need the car to be \n  physically present at the car wash to get it cleaned. \n\n  Do I Do Better?\n\n  Yes, I do. The key is understanding the objective (cleaning the car) rather than just \n  processing the keywords (distance/transportation). \n\n  My answer:\n\n    You should drive the car there. Even though it is a very short distance, your car \n    cannot wash itself. If you walk, the car stays in your driveway, and you cannot wash it.\n\n  Why This Matters\n  \n  The test highlights a key limitation in current AI: the difference between \"pattern matching\" \n  (predicting the next likely word based on training data) and \"true, grounded reasoning\". It \n  shows that models sometimes lack a \"world model\" that understands physical realities, such as\n  the fact that a car must be present at a car wash.",
          "author": "PaulHoule",
          "replies": [
            {
              "text": "LLMs sure do love to burn tokens. It’s like a high schooler trying to meet the minimum word length on a take home essay.",
              "author": "gnatman",
              "depth": 1
            },
            {
              "text": "The long incremental reasoning is how they arrive at higher quality answers.\nSome applications hide the reasoning tokens from view, but then the final answer appears delayed.",
              "author": "Aurornis",
              "depth": 2
            },
            {
              "text": "I feel like this has gotten much worse since they were introduced. I guess they're optimizing for verbosity in training so they can charge for more tokens. It makes chat interfaces much harder to use IMO.\nI tried using a custom instruction in chatGPT to make responses shorter but I found the output was often nonsensical when I did this",
              "author": "sambaumann",
              "depth": 2
            },
            {
              "text": "Yeah, ChatGPT has gotten so much worse about this since the GPT-5 models came out. If I mention something once, it will repeatedly come back to it every single message after regardless of if the topic changed, and asking it to stop mentioning that specific thing works, except it finds a new obsession. We also get the follow up \"if you'd like, I can also...\" which is almost always either obvious or useless.\nI occasionally go back to o3 for a turn (it's the last of the real \"legacy\" models remaining) because it doesn't have these habits as bad.",
              "author": "gs17",
              "depth": 3
            },
            {
              "text": "It's similar for me, it generates so much content without me asking. if I just ask for feedback or proofreading smth it just tends to regenerate it in another style. Anything is barely good to go, there's always something it wants to add",
              "author": "felix089",
              "depth": 4
            }
          ]
        }
      ]
    },
    {
      "id": "47123631",
      "title": "Show HN: PgDog – Scale Postgres without changing the app",
      "link": "https://github.com/pgdogdev/pgdog",
      "domain": "github.com",
      "author": "levkk",
      "score": 314,
      "comment_count": 57,
      "created_ts": 1771860804,
      "is_internal": false,
      "post_text": "Hey HN! Lev and Justin here, authors of PgDog (<a href=\"https:&#x2F;&#x2F;pgdog.dev&#x2F;\">https:&#x2F;&#x2F;pgdog.dev&#x2F;</a>), a connection pooler, load balancer and database sharder for PostgreSQL. If you build apps with a lot of traffic, you know the first thing to break is the database. We are solving this with a network proxy that works without requiring application code changes or database migrations.<p>Our post from last year: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44099187\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44099187</a><p>The most important update: we are in production. Sharding is used a lot, with direct-to-shard  queries (one shard per query) working pretty much all the time. Cross-shard (or multi-database) queries are still a work in progress, but we are making headway.<p>Aggregate functions like count(), min(), max(), avg(), stddev() and variance() are working, without refactoring the app. PgDog calculates the aggregate in-transit, while transparently rewriting queries to fetch any missing info. For example, multi-database average calculation requires a total count of rows to calculate the original sum. PgDog will add count() to the query, if it’s not there already, and remove it from the rows sent to the app.<p>Sorting and grouping works, including DISTINCT, if the columns(s) are referenced in the result. Over 10 data types are supported, like, timestamp(tz), all integers, varchar, etc.<p>Cross-shard writes, including schema changes (CREATE&#x2F;DROP&#x2F;ALTER), are now atomic and synchronized between all shards with two-phase commit. PgDog keeps track of the transaction state internally and will rollback the transaction if the first phase fails. You don’t need to monkeypatch your ORM to use this: PgDog will intercept the COMMIT statement and execute PREPARE TRANSACTION and COMMIT PREPARED instead.<p>Omnisharded tables, a.k.a replicated or mirrored (identical on all shards), support atomic reads and writes. That’s important because most databases can’t be completely sharded and will have some common data on all databases that has to be kept in-sync.<p>Multi-tuple inserts, e.g., INSERT INTO table_x VALUES ($1, $2), ($3, $4), are split by our query rewriter and distributed to their respective shards automatically. They are used by ORMs like Prisma, Sequelize, and others, so those now work without code changes too.<p>Sharding keys can be mutated. PgDog will intercept and rewrite the update statement into 3 queries, SELECT, INSERT, and DELETE, moving the row between shards. If you’re using Citus (for everyone else, Citus is a Postgres extension for sharding databases), this might be worth a look.<p>If you’re like us and prefer integers to UUIDs for your primary keys, we built a cross-shard unique sequence, directly inside PgDog. It uses the system clock (and a couple other inputs), can be called like a Postgres function, and will automatically inject values into queries, so ORMs like ActiveRecord will continue to work out of the box. It’s monotonically increasing, just like a real Postgres sequence, and can generate up to 4 million numbers per second with a range of 69.73 years, so no need to migrate to UUIDv7 just yet.<p><pre><code>    INSERT INTO my_table (id, created_at) VALUES (pgdog.unique_id(), now());\n</code></pre>\nResharding is now built-in. We can move gigabytes of tables per second, by parallelizing logical replication streams across replicas. This is really cool! Last time we tried this at Instacart, it took over two weeks to move 10 TB between two machines. Now, we can do this in just a few hours, in big part thanks to the work of the core team that added support for logical replication slots to streaming replicas in Postgres 16.<p>Sharding hardly works without a good load balancer. PgDog can monitor replicas and move write traffic to a promoted primary during a failover. This works with managed Postgres, like RDS (incl. Aurora), Azure Pg, GCP Cloud SQL, etc., because it just polls each instance with “SELECT pg_is_in_recovery()”. Primary election is not supported yet, so if you’re self-hosting with Patroni, you should keep it around for now, but you don’t need to run HAProxy in front of the DBs anymore.<p>The load balancer is getting pretty smart and can handle edge cases like SELECT FOR UPDATE and CTEs with INSERT&#x2F;UPDATE statements, but if you still prefer to handle your read&#x2F;write separation in code, you can do that too with manual routing. This works by giving PgDog a hint at runtime: a connection parameter (-c pgdog.role=primary), SET statement, or a query comment. If you have multiple connection pools in your app, you can replace them with just one connection to PgDog instead. For multi-threaded Python&#x2F;Ruby&#x2F;Go apps, this helps by reducing memory usage, I&#x2F;O and context switching overhead.<p>Speaking of connection pooling, PgDog can automatically rollback unfinished transactions and drain and re-sync partially sent queries, all in an effort to preserve connections to the database. If you’ve seen Postgres go to 100% CPU because of a connection storm caused by an application crash, this might be for you. Draining connections works by receiving and discarding rows from abandoned queries and sending the Sync message via the Postgres wire protocol, which clears the query context and returns the connection to a normal state.<p>PgDog is open source and welcomes contributions and feedback in any form. As always, all features are configurable and can be turned off&#x2F;on, so should you choose to give it a try, you can do so at your own pace. Our docs (<a href=\"https:&#x2F;&#x2F;docs.pgdog.dev\">https:&#x2F;&#x2F;docs.pgdog.dev</a>) should help too.<p>Thanks for reading and happy hacking!",
      "is_ask_hn": false,
      "matched_keywords": [
        "team",
        "feedback"
      ],
      "comments": [
        {
          "top": "As someone who has worked on many-TB-sized \"custom\" sharded systems with 30-150 shards at multiple (ok, 2) employers, a key challenge to the overall sharding landscape is unsharding all the data back at the analytics layer.\nThis at a minimum often involved adding back a shard key to the physical data, or partitioning, and/or physical data sorting easily in the \"OLAP\" layer. And a surprising number of CDC and ETL toolkits don't make it easy to parameterize a single code/configuration base, nor handle situations like shards being down at different times for maintenance or fetching data from each shard at a time of day specified by its end-of-day or handling retransmissions or reconciliation or gaps or data quality of a single shard when back in an unsharded landscape. SQL UNION ALL to reunite shards works, until it doesn't.\nYMMV but would be curious if you have a story/solution/thoughts along these lines. It's easier if you shard with unified analytics/reporting in mind on day one of a sharded system design, but in the worlds I've lived in, nobody ever does. But maybe you could.",
          "author": "gregw2",
          "replies": [
            {
              "text": "A couple options come to mind:\n1. Replicate shards into one beefy database and use that. Replication is cheaper than individual statements, so this can work for a while. The sink can be Postgres or another database like Clickhouse. At Instacart, we used Snowflake, with an in-house CDC pipeline. It worked well, but Snowflake was only usable for offline analytics, like BI / batch ML, and quite expensive. We'll add support for this eventually; we're getting pretty good at managing logical replication, including DDL changes.\n2. Use the shards themselves and build a decent query engine on top. This is the Citus way and we know it's possible. Some queries could be expensive, but that's expected and can be solved with more compute.\nIn our architecture, shards going down for maintenance is an incident-level event, so we expect those to be up at all times, and failover to a standby if there is an issue. These days, most maintenance tasks can be done online in-place, or with blue/green, which we'll support as well. Zero downtime is the name of the game.",
              "author": "levkk",
              "depth": 1
            }
          ]
        },
        {
          "top": "Great progress, guys! It’s impressive to see all the enhancements - more types, more aggregate functions, cross-node DML, resharding, and reliability-focused connection pooling and more. Very cool! These were really hard problems and took multiple years to build at Citus. Kudos to the shipping velocity.",
          "author": "saisrirampur",
          "replies": []
        },
        {
          "top": "Happy pgdog user here, I can recommend it from a user perspective as a connection pooler to anyone checking this out (we're also running tests and positive about sharding, but haven't run it in prod yet, so I can't 100% vouch for it on that, but that's where we're headed.)\n@Lev, how is the 2pc coming along? I think it was pretty new when I last checked, and I haven't looked into it much since then. Is it feeling pretty solid now?",
          "author": "mijoharas",
          "replies": [
            {
              "text": "It feels better now, but we still need to add crash protection - in case PgDog itself crashes, we need to restore in-progress 2pc transaction records from a durable medium. We will add this very soon.",
              "author": "levkk",
              "depth": 1
            }
          ]
        },
        {
          "top": "Stupid question but does this shard the database as well or do we shard manually and then setup the configuration accordingly ?",
          "author": "codegeek",
          "replies": [
            {
              "text": "It shards it as well. We handle schema sync, moving table data (in parallel), setting up logical replication, and application traffic cutover. The zero-downtime resharding is currently WIP, working on the PR as we speak: \nhttps://github.com/pgdogdev/pgdog/pull/784\n.",
              "author": "levkk",
              "depth": 1
            },
            {
              "text": "Incredible. I am really interested in trying pgdog for our B2B SAAS product. Will do some testing.",
              "author": "codegeek",
              "depth": 2
            },
            {
              "text": "Interesting, I'm a bit new to this... could you explain how PgDog works high-level? It's both a connection pooler and a sharding engine? Is there a kind of tutorial to \"play\" with those features and get a sense of how they work/what complexity they add?",
              "author": "oulipo2",
              "depth": 2
            }
          ]
        },
        {
          "top": "Some HTTP proxies can do retries -- if a connection to one backend fails, it is retried on a different backend. Can PgDog (or PgBouncer, or any other tool) do something similar -- if there's a \"database server shutting down\" error or a connection reset, retry it on another backend?",
          "author": "cuu508",
          "replies": [
            {
              "text": "Not currently, but we can add this. One thing we have to be careful of is to not retry requests that are executing inside transactions, but otherwise this would be a great feature.",
              "author": "levkk",
              "depth": 1
            }
          ]
        }
      ]
    },
    {
      "id": "47136537",
      "title": "IRS Tactics Against Meta Open a New Front in the Corporate Tax Fight",
      "link": "https://www.nytimes.com/2026/02/24/business/irs-meta-corporate-taxes.html",
      "domain": "www.nytimes.com",
      "author": "mitchbob",
      "score": 188,
      "comment_count": 199,
      "created_ts": 1771937894,
      "is_internal": false,
      "post_text": "",
      "is_ask_hn": false,
      "matched_keywords": [
        "corporate"
      ],
      "comments": [
        {
          "top": "I wrote about this 20 years ago:\nhttp://digital-majority.wikidot.com/forum/t-5766/software-pa...\nIn the meantime, Ireland removed their 0% tax over patent royalties, but Holland kept it at 0%.\nhttps://en.wikipedia.org/wiki/Double_Irish_arrangement",
          "author": "zoobab",
          "replies": [
            {
              "text": "Oh it was the EU that closed it down? didn't even know this ended as an option",
              "author": "SpaceManNabs",
              "depth": 1
            },
            {
              "text": "Your 20y old site gave me https errors when I tried to click it, fyi",
              "author": "bobthepanda",
              "depth": 1
            },
            {
              "text": "Don't access it over https then? The link is http.",
              "author": "q3k",
              "depth": 2
            },
            {
              "text": "Don't modern browsers automatically redirect http to https?",
              "author": "LoganDark",
              "depth": 3
            },
            {
              "text": "No they don't. I tried Chrome, Firefox, and Safari. None of them attempted to redirect. They just show a \"not secure\" warning in the URL bar.\nThe redirect only happens when it's configured on the web server, set in HSTS, or on a TLD that enforces HTTPS. None of these apply to this website.",
              "author": "Gigachad",
              "depth": 4
            }
          ]
        },
        {
          "top": "Corporation tax is so annoying, with so many r&d caveats etc. Just tax outflows.",
          "author": "philipallstar",
          "replies": []
        },
        {
          "top": "> contending the company lowballed the price of trademarks, customer agreements, software licenses and other rights it moved offshore\nAt the same time they were telling HMRC (the British tax authority) that IP rights, etc. were incredibly valuable and a significant cost of doing business (in the form of payments back to the mothership), and that's why they made very little profit in the UK and didn't need to pay much tax.",
          "author": "masfuerte",
          "replies": [
            {
              "text": "Trying to trace more detail on this: \nhttps://www.taxwatchuk.org/seven-large-tech-groups-estimated...\nThat mentions the digital services tax; I remember some of HN being quite angry that \"Europe\" was trying to get a share of the immense wealth extracted from it by American multinationals.",
              "author": "pjc50",
              "depth": 1
            },
            {
              "text": "Wealth extracted from a company sounds like taxes.",
              "author": "Muromec",
              "depth": 2
            },
            {
              "text": "How did we go from \"wealth extracted from [Europeans and Europe]\" to \"wealth extracted from a company\"?",
              "author": "bjustin",
              "depth": 3
            },
            {
              "text": "What you mean is American multinationals were inventing things people wanted to pay for and the existing government rent seeking wasn't working.",
              "author": "philipallstar",
              "depth": 2
            },
            {
              "text": "\"Wealth extracted from it\" seems like a disingenuous framing of \"voluntary market exchange of money for services.\"  It's not like Europe is a colony.  Tech companies only make money by providing goods and services people choose to pay for.",
              "author": "loeg",
              "depth": 2
            }
          ]
        },
        {
          "top": "Differential pricing schemes are the primary way Corporations avoid corporate income taxes.  I remember reading an article by an old Africa hand where he quoted the manager of an international corporation being exasperated with him and saying \"You think I'm actually trying to make money here?  This is all about taxes.\"\nIn theory overpaying for modules produced by your subsidiary, or overpricing IP, in a low tax country is illegal, at least in the US, but so much of that is subjective it's difficult for tax authorities to actually do anything unless the numbers are eggregious.",
          "author": "laughing_man",
          "replies": []
        },
        {
          "top": "> The agency is using real-world profit data to challenge how big companies value offshore intellectual property.\nhttps://archive.ph/2026.02.24-124153/https://www.nytimes.com...",
          "author": "mitchbob",
          "replies": [
            {
              "text": "Probably less about tax revenue and more about the executive branch squeezing tech companies to assert influence.",
              "author": "notyourwork",
              "depth": 1
            },
            {
              "text": "> Probably less about tax revenue and more about the executive branch squeezing tech companies to assert influence.\nAbsolutely \nnot\n about this, as is clearly reported in the linked article.",
              "author": "bonsai_spool",
              "depth": 2
            },
            {
              "text": "Because the article said so? That’s your rationale for saying the executive branch isn’t weaponizing the rest of government offices for their own influence and benefit. Sorry, color me unconvinced until this administration shows good faith.",
              "author": "notyourwork",
              "depth": 3
            },
            {
              "text": "> Because the article said so?\nBecause... the article clearly says the case began under the \nFORMER\n administration, and goes further to say that it's not clear whether the \nCURRENT\n administration is going to drop the case.",
              "author": "bonsai_spool",
              "depth": 4
            },
            {
              "text": "Am I the only one who thinks it's totally bonkers that a lawsuit can outlast a 4 year presidential administration? I mean, I get it, court cases can be complex, but what on earth could they be continuously doing for four years? I would love to see an hour by hour accounting of the time actually spent by humans on a case like this. My guess is that it's like a poorly run software project: mostly empty, where Person X is blocked waiting on the output of Person Y for weeks, and so on.",
              "author": "ryandrake",
              "depth": 5
            }
          ]
        }
      ]
    },
    {
      "id": "47123894",
      "title": "Show HN: Sowbot – Open-hardware agricultural robot (ROS2, RTK GPS)",
      "link": "https://sowbot.co.uk/",
      "domain": "sowbot.co.uk",
      "author": "Sabrees",
      "score": 177,
      "comment_count": 45,
      "created_ts": 1771861713,
      "is_internal": false,
      "post_text": "Sowbot is an open-hardware agricultural robot designed to close the &quot;prototype gap&quot; that kills most agri-robotics startups and research projects — the 18+ months spent on drivers, networking, safety watchdogs, and UI before you can even start on the thing you actually care about.<p>The hardware is built around a stackable 10×10cm compute module with two ARM Cortex-A55 SBCs — one for ROS 2 navigation&#x2F;EKF localisation, one dedicated to vision&#x2F;YOLO inference — connected via a single ethernet cable.<p>Centimetre-level positioning via dual RTK GNSS, CAN bus for field comms, and real-time motor control via ESP32 running Lizard firmware.<p>Everything — schematics, PCB layouts, firmware — is under open licences.\nThe software stack runs on RoSys&#x2F;Field Friend (for teams who want fast iteration) or DevKit ROS (for teams already in the ROS ecosystem). The idea is that a lab in one country can reproduce another lab&#x27;s experiment by sharing a Docker image.<p>Current status: the Open Core brain is largely fabricated, the full-size Sowbot body has a detailed BOM but isn&#x27;t yet assembled, and we have two smaller dev platforms (Mini and Pico) in various stages of testing.<p>We&#x27;re a small volunteer team and we&#x27;re looking for contributors — hardware, ROS, firmware, docs, whatever you can offer.<p>The best place to start is our Discord: <a href=\"https:&#x2F;&#x2F;discord.gg&#x2F;SvztEBr4KZ\" rel=\"nofollow\">https:&#x2F;&#x2F;discord.gg&#x2F;SvztEBr4KZ</a> — we have a weekly call if you&#x27;d prefer to just show up and chat.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Agroecology-Lab&#x2F;feldfreund_devkit_ros&#x2F;tree&#x2F;caatinga-dev\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Agroecology-Lab&#x2F;feldfreund_devkit_ros&#x2F;tre...</a>",
      "is_ask_hn": false,
      "matched_keywords": [
        "networking",
        "team"
      ],
      "comments": [
        {
          "top": "> The hardware is built around a stackable 10×10cm compute module with two ARM Cortex-A55 SBCs — one for ROS 2 navigation/EKF localisation, one dedicated to vision/YOLO inference — connected via a single ethernet cable.\nI will preface this by saying that I have nothing against ARM per se, that my employer/team supported a good chunk of the work for making ROS 2 actually work on arm64, and that there is some good hardware out there.\nI really don't understand why startups and research projects keep using weird ARM SBCs for their robots. The best of these SBCs is still \nvastly\n shittier in terms of software support and stability than any random Chinese Intel ADL-N box. The only reasons to use (weird) ARM SBCs in robots are that either (1) you are using a Jetson for Jetson things (i.e. Nvidia libraries), or (2) you have a product which requires serious cost optimization to be produced at a large scale. Otherwise you are just committing yourselves and your users/customers to a future of terrible-to-nonexistent support and adding significantly to the amount of work you need to bring up the new system and port existing tools to it.",
          "author": "cpgxiii",
          "replies": [
            {
              "text": "> The only reasons to use ARM SBCs in robots are...\nObviously, anyone can have there own opinion on this.  \nI work in robotics, we are quite happy with our A53 and M4.  Though, we use a SOM, not a SBC, if you feel like splitting hairs.",
              "author": "schaefer",
              "depth": 1
            },
            {
              "text": "You probably aren't using some weird SOM, though. There is a bit of an unstated exception of \"unless said SBC/SOM has specific hardware that is necessary/particularly valuable for your product/project\". For example, if you need GMSL you are probably not going to be picking Intel, even though ADL-N and the bigger processors support MIPI, simply because no one else does and the documentation/support for it is basically nonexistent. Designs with closely-coupled A/M/R cores, or CPU/MCU/FPGA hybrids like Zynq would be others.\nBut generally projects which are choosing some random SBC aren't using any of these features, and are just suffering the pain/imposing it on their users for no good reason.",
              "author": "cpgxiii",
              "depth": 2
            },
            {
              "text": "again, just an oppinion, but it feels really weird to hear you find \"exception after exception\", when the net result that you've ruled out more real world robotics projects on ARM than likely exist on x86 that you're suggesting should be the \"norm\".\nyou've ruled out the entire NXP ecosystem, the entire Nvidia Jetson ecosystem, the entire AMD/FPGA/Zynq ecosystem, even perfectly good options like beagle-board .... who else?\nincidentally, you've also ruled out this project - as they are using an M7 microcontroller to meet their hard-real-time timing constraints...",
              "author": "schaefer",
              "depth": 3
            },
            {
              "text": "The other poster had said nothing about microcontrollers, e.g. about the various MCU models based on Cortex-M cores.\nSome things are best done with a microcontroller, and those are not suitable for being done with a general-purpose CPU either based on Intel/AMD or on Cortex-A cores. Actually there are many projects that mistakenly use something like a Raspberry Pi instead of a better and cheaper implementation with a microcontroller, e.g. one based on Cortex-M7 or its successor, Cortex-M85.\nThe other poster said that where you do not want a microcontroller, but you want to run a standard operating system, e.g. Linux, then the best choice is much more frequently a SBC with an Intel Alder Lake N or Twin Lake CPU, as these not only have a better performance per dollar than the ARM-based SBCs, but they also avoid any software problems and future maintainability problems.\nUnfortunately, during the last few months the price of Intel-based SBCs has been affected by the fact that most of them do not have soldered memory but they use one SODIMM memory module. While you can buy an Intel Alder Lake N based SBC for $100, buying today a SODIMM for it may cost as much or more, depending on the amount of memory with which you are content.\nThe ARM SBCs that come with soldered LPDDR memory have initially been less affected by the price hikes, though now even for them the prices are rising.",
              "author": "adrian_b",
              "depth": 4
            },
            {
              "text": "I think you're missing my point entirely. If your project needs specific hardware, you have to use that specific hardware (the obvious examples of which would be Jetsons or Zynq/Zynq-like or something ASIL-D or something that tightly couples \"A\"/M/R cores together, or you are stuck using a SoC from Qualcomm for cell connectivity). There are a lot of projects that do fall into that category.\nThere are also a (much smaller) number of projects that will legitimately see the kind of scale of production that justifies aggressive cost optimization for the compute platform, either in terms of designing their own around a SoC or picking some SBC/SoM that they can get a good deal on, where the significant additional up-front engineering cost is outweighed by the production savings (and where the desire/need to keep a fixed platform means the often limited platform support from the vendor is less restrictive).\nBut a large number of robotics projects (basically everything in the research sphere) - this one very much included - just need \"some computer\" for general-purpose use. They are already separating realtime control onto a separate microcontroller board. For these projects, it is almost always committing a \"premature pessimization\" of picking some weird SBC. You are signing up for worse CPU and GPU performance, stability, and development future for very little reward.",
              "author": "cpgxiii",
              "depth": 4
            }
          ]
        },
        {
          "top": "Looks great for a prototype. Has any modeling, simulation, or analysis been done of its off-road performance, i.e. mobility, GO/NOGO, motive efficiency, maneuverability on deformable terrain? This is critical for agricultural applications.\nHas any stress analysis been done on the frame? Looks to me like it could use a couple more triangles to reinforce those rectangles.\nHave you designed a skid-steering controller for it? Off-road skid steering can be quite variable obviously depending on terrain properties.",
          "author": "lorenzohess",
          "replies": [
            {
              "text": "Rosys (a middleware layer \nhttps://github.com/zauberzeug/rosys\n) has rosys.driving.Odometer and rosys.driving.Steerer it's essentially a differential drive kinematic model.\nHoping RTK dual-F9P moving-base setup (M4 in the roadmap) largely sidesteps the worst of this — NAV-RELPOSNED gives us a real heading vector independent of wheel odometry, and the robot_localisation EKF can weight RTK heavily and odometry lightly when GNSS quality is good.",
              "author": "Sabrees",
              "depth": 1
            },
            {
              "text": "The current simulation is underdeveloped but can be found here \nhttps://github.com/samuk/caatingarobotics/tree/jazzy/src/agr...\nThe frame will almost certainly need more triangles",
              "author": "Sabrees",
              "depth": 1
            }
          ]
        },
        {
          "top": "Australia's been working with various types of robotics in agriculture since 1980 at least [1], these days, for open field work there are several families of solution in developmental progress.\nOne leading contender is SwarmFarm Robotics, based out of Queensland.\n* \nhttps://advance.qld.gov.au/innovation-in-queensland/innovati...\n* \nhttps://www.swarmfarm.com/\nFor interest, here's a recent opinion / demonstration from an unassociated Australian farmer considering a purchase.\nThe farm is Tom’s Brook, a grain farm located in Esperance in Western Australia. It’s a family operated business growing a mixture of Wheat, Barley and Canola on 4500 hectares (11 200 Acres). Sizewise is pretty much bang on the average W.Australian grain acerage.\nSeeing a Swarm Bot in Action\n (20 min) - \nhttps://www.youtube.com/watch?v=ljEKN7CsjnM\nThe unit pair in action here, autonomous tractor pulling intelligent boom spray, has had 10,000 acres of operation prior to this customer demonstration.\nUnloaded weight ~ 3.5 metric tonne, loaded approx 5 tonne.\nRuns at about 13 hectares per hour, max speed 10 km/hour.\nAdvantages of \"intelligence\" during operation are reduced spray usage (basic green on dirt detection, and green shape on mixed green patterns) and weather patience (happy to sit idle until wind and humidity are optimal)\n70 odd Comments include feedback from other farmers already using such agribots, eg:\n  Just rolled over 12,000 hrs on our swarmbot.  4 years, 3000hr a year, doesn't get into the shed much.\n\n\nThe first 12 minutes are Vendor + Farmer discussing bot in action, remaining eight minutes is farmer and hands discussing pros and cons.\n--\n[1] Robot Sheep Shearing (1985) \nhttps://www.youtube.com/watch?v=6ZAh2zv7TMM",
          "author": "defrost",
          "replies": []
        },
        {
          "top": "Very cool! shameless self promotion but check out greenwave-monitor[1] for the 'Diagnostics TUI'. I'll get it into the buildfarm soon.\n[1] \nhttps://github.com/NVIDIA-ISAAC-ROS/greenwave_monitor",
          "author": "sgillen",
          "replies": [
            {
              "text": "Nice, thanks! looks like a good one..",
              "author": "Sabrees",
              "depth": 1
            }
          ]
        },
        {
          "top": "I wonder how good is the cooling of the stacked \"robot brain\".\nIt would be nice to see some temperatures in relevant points, when the computer is stress tested in the closed waterproof case and a hot ambient.\nThe Cortex-A55 based CPU has low power consumption, but it is not negligible and without a heatsink it may overheat and throttle.\nMoreover, in a closed box, one may need some means to transfer the heat from the stacked electronics to the aluminum walls of the box. Finding suitable means may be more complex for this design, because of the curious choice of using 2 weak SBCs instead of 1 good SBC, so there are 2 sets of CPU + memories that must be cooled.\nFrom the provided pictures, I cannot see how the electronics would be cooled well enough, especially when working outdoors during a hot day.",
          "author": "adrian_b",
          "replies": []
        }
      ]
    },
    {
      "id": "47128535",
      "title": "Show HN: Babyshark – Wireshark made easy (terminal UI for PCAPs)",
      "link": "https://github.com/vignesh07/babyshark",
      "domain": "github.com",
      "author": "eigen-vector",
      "score": 140,
      "comment_count": 45,
      "created_ts": 1771879534,
      "is_internal": false,
      "post_text": "Hey all, I built babyshark, a terminal UI for PCAPs aimed at people who find Wireshark powerful but overwhelming.<p>The goal is “PCAPs for humans”:\nOverview dashboard answers what’s happening + what to click next<p>Domains view (hostnames first) → select a domain → jump straight to relevant flows\n(works even when DNS is encrypted&#x2F;cached by using observed IPs from flows)<p>Weird stuff view surfaces common failure&#x2F;latency signals (retransmits&#x2F;out-of-order hints, resets, handshake issues, DNS failures when visible)<p>From there you can drill down: Flows → Packets → Explain (plain-English hints) &#x2F; follow stream<p>Commands:\nOffline: babyshark --pcap capture.pcap<p>Live (requires tshark): babyshark --list-ifaces then babyshark --live en0<p>Repo + v0.1.0 release: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vignesh07&#x2F;babyshark\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vignesh07&#x2F;babyshark</a><p>Would love feedback on UX + what “weird detectors” you’d want next.",
      "is_ask_hn": false,
      "matched_keywords": [
        "failure",
        "feedback"
      ],
      "comments": [
        {
          "top": "I am in the target audience of \"would like to see network activity and debug occasional traffic but totally overwhelmed by termshark.\" So I appreciate the \"what should I click?\" thing, and offering weird flows to investigate.\n---\nSome UX bits I noticed after playing around for a few minutes:\n- Esc for backwards navigation was not obvious for me. Maybe emphasize that somehow, and/or support Backspace too for backnav?\n- Enter on Domains menu item does not work\n- don't mention clicking if mouse is not supported. \"Select\" would be more appropriate\n- packets screen is truncated vertically and horizontally. Probably should be scrollable\n- \"weird stuff\" options are numbered 1-5, but pressing those keys has no effect. There's lots of little polish fixes like this.\n---\nAnd then things I wonder about as a novice user:\n- Is it possible to see domain names instead of IP addresses while e.g. looking at packets?\n- What does it mean to f stream?\n- How do I inspect packets? Especially compressed or encrypted data? This is more a knowledge gap, like \"what am I supposed to look for\", \"what could be in a packet\", and I guess involves reverse engineering sometimes, but it's also a tooling question.",
          "author": "wonger_",
          "replies": [
            {
              "text": "Thanks a lot for trying. My experience with packet inspection is similar and that's what resulted in me trying to build a simpler plain language UI companion.\n• Back navigation: good call. I'll make \"Esc back\" more explicit everywhere and add Backspace as an alias for back (and mention it in h help).\n• Enter on Domains not working: it should drill down to flows. If you can share your OS/terminal + whether you installed from release vs cargo install, I'll try to reproduce and fix in the next release.\n• \"Clicking\" wording: agreed — mouse isn't supported right now. I'll change Ul copy to say Select (and keep \"Enter = drill down\").\n• Packets screen truncation: yep, needs scrolling/paging. On the list views I already do r/; l'll add page scroll and horizontal handling where it makes sense.\n• Numbered weird options: great idea - I'll map 1..9 to jump-select and Enter (or open directly).\n• Domain names in packets: yes, I want that. I already collect DNS/SNI/HTTP host hints; next step is showing hostname labels alongside IPs when I have more confident mapping.\n• \"f stream\" definition: I'll clarify it as \"Follow stream (reassembled payload)\" and add a glossary/help entry.\n• Inspecting encrypted/compressed data: totally fair. The tool can't decrypt TLS without keys, but it can make it clearer what's happening (SNI/ ALPN, sizes, timing, resets/retransmits). I'Il improve \"Explain\" to say what's possible vs not.\nSuper useful feedback thanks!",
              "author": "eigen-vector",
              "depth": 1
            },
            {
              "text": "All this has been pushed to main. Thanks again!",
              "author": "eigen-vector",
              "depth": 2
            },
            {
              "text": "Another UI question: is there a reason the options are all upper case letters? It took me a minute to even consider why \"w\" wasn't working.",
              "author": "tclancy",
              "depth": 2
            },
            {
              "text": "Sorry that was a miss on my part. I fixed it in the latest main. Will recognize both in the next release.",
              "author": "eigen-vector",
              "depth": 3
            }
          ]
        },
        {
          "top": "the overwhelming part of wireshark is, at least in my experience teaching networking at a college level, the actual networking part. protocols, flows, packet structure, etc. kids tend to be up to speed on the UI part pretty quickly.\nwhat the kids in my classes really struggle with is actually using any command line stuff (at least for a month or two), because it is so foreign to them (coming from GUI-only experience).\nwhat specific parts are made easier with babyshark, compared to wireshark? the github readme didnt really sell me on the \"easier than GUI\" part, nor did your description here. is it the \"explain (plan-English hints)\" part? if so, i think you should focus on that. right now it looks pretty bare bones (e.g. \"Weird stuff\" does not seem easier or super helpful from a learning perspective)",
          "author": "john_strinlai",
          "replies": [
            {
              "text": "I remember going into my networking unit and absolutely destroying it through the use of the command line. Everyone else was clicking through the wireshark GUI and I just grepped every answer. Finished the hour long practical assessment in about 15 minutes having run everything twice.\nCLI is so valuable because rather than explore a presentation of the data you plan your RE etc and then run it and it either returns the answer or it doesn't.\nThere are some TUIs I quite like (LNAV as a pager) but I think if you really know what you're dealing with the CLI is better almost every time.",
              "author": "Affric",
              "depth": 1
            },
            {
              "text": "There's a layer above that, when CLI and bash and sed and tshark are becoming too hairy or slow, and it's 'just' parsing the pcap frames in your language of productivity. Over the years I've built layer over layer of optimized Java code to parse and analyze pcap/pcapng files with either visitor patterns or active iterations (and multi-pass analyses through indexation, or just interfacing with duckdb for months-long-capture analysis to surface low signal-to-noise-ratio events). It builds a good understanding of all the layers and brings the power of a full-featured workbench (language, IDE, libraries, visualization options...).\nBuilt it in Java, and rebuilt it in Ada, and Rust. I find it's a good exercise to learn about a programming language... bonus point, once I have a parser, plugging it live behind libpcap, dpdk, xdp, or just raw sockets is easy.",
              "author": "touisteur",
              "depth": 2
            },
            {
              "text": "I'm not trying to say it's better than the GUI but it hopes to be more guided. it’s *opinionated* about the first 60 seconds:\n- *Overview dashboard*: immediately surfaces top talkers/flows + “what should I click next” instead of dropping you into the full packet list.\n- *Domains-first pivot*: `D` shows hostnames and lets you jump from a domain → the relevant flows. It also works when DNS answers aren’t visible (DoH/DoT/cached) by using \nobserved IPs from SNI/Host flows\n.\n- *Weird stuff*: `W` is a curated set of “likely problems” (retransmits/out-of-order hints, resets, handshake issues, DNS failures when visible) with a short “why it matters” and a drill-down.\n- *Explain*: `?` gives plain-English hints for a selected flow + suggested next steps (follow stream, filter, pivot to domains/weird).\nSo it’s basically a guided triage layer on top of tshark/pcap data, with the “where do I start?” path baked in.\nIf you’ve got a specific teaching use-case (e.g. “why is this slow?” or “which host is generating traffic?”), I’d love to tune the Overview/Weird detectors around that. Open to PRs as well.",
              "author": "eigen-vector",
              "depth": 1
            },
            {
              "text": ">\nSo it’s basically a guided triage layer on top of tshark/pcap data, with the “where do I start?” path baked in.\ni think there is definitely room for something like this, it just (at first glance from the readme at least) seems like the guided part of this tool is bolted on as a bit of an after thought.\nit feels like you are currently in an odd position where the user is expected to know the networking jargon already, be able to recognize that something might be \"weird\" at a glance, but \nalso\n not know how to drill down into the data. i think that is probably a small overlap of people.\nif i were you, i would lean all-in on making it a learning tool.\n>\nIf you’ve got a specific teaching use-case (e.g. “why is this slow?” or “which host is generating traffic?”), I’d love to tune the Overview/Weird detectors around that.\ni will put some thought into some real-world examples of what i would be interested in, from a teaching perspective. your post caught my eye because i am starting my wireshark module next week, so it is certainly timely.",
              "author": "john_strinlai",
              "depth": 2
            },
            {
              "text": "Yeah, right now it's closer to \"triage for non-experts\" than \"full teaching tool,\" and l agree there's an awkward middle where it assumes you recognize some concepts (flows/ports/latency) while trying to help with the drilldown.\nThe direction I want to push it in is exactly what you're describing; make it a learning tool, where each detector/view answers:\n1) What am I seeing? (plain language)\n2) Why might it matter?\n3) What's the next click?\n4) What term should I learn? (glossary link)\nIf you're about to teach a Wireshark module next week, two super useful things would be:\n• 3-5 common lab prompts you give students (e.g.\n\"identify the DNS failure,\" \"find the top talker,\"\n\"spot a TCP reset,\" \"why is this slow?\")\n• one small pcap you already use (or even just describe its scenario)\nI can tune Overview/Weird/Explain around those and make the guided layer feel like the main product rather than a thin overlay.\nAlso: if your students are GUl-only early on, that's a good callout - I should improve the README to frame Babyshark as \"guided analysis,\" not\n\"terminal is easier than GUI.\"\nI'm also happy for your students to get hands on by sending PRs for things they wish are intuitive from the get go.",
              "author": "eigen-vector",
              "depth": 3
            }
          ]
        },
        {
          "top": "This might be a clone of termshark as it does the same thing for the most part. Also to note that the Author's Github profile shows a good bit of vibe coding as of late.\nLooking over the commit history of this project, I'm about 90% sure it was entirely done with a AI Coding Agent, and not even a very good one.",
          "author": "jetbalsa",
          "replies": [
            {
              "text": "It probably is somewhat LLM prompted but is that a bad thing?\nI have a business partner who sounds like a TV evangelist when it comes to vibe coding but if he gets results then I am all in.  He has got quite a lot of results in a few months on a project but he has certainly put the miles in himself.\nThe key is to use the tool appropriately.  Don't blindly allow it to do what it likes but guide it all the way using your experience and knowledge.\nAnyway, we now have tsharkrs to add to gotshark!",
              "author": "gerdesj",
              "depth": 1
            },
            {
              "text": "Oh Don't get me wrong, I Vibe code the shit of my projects nowadays, but I don't think any of them deserve a Show HN even after I've spent a week polishing them. Claude Code is like crack to my ADHD Programmer brain",
              "author": "jetbalsa",
              "depth": 2
            },
            {
              "text": "Thanks for the look. Babyshark is inspired by a bunch of terminal tools (termshark included), but the focus here is different: domains/weirdness-first drilldowns + \"explain\" + live-mode hostname hints (including observed IPs when DNS is encrypted/cached). If you try it and have specific gaps vs termshark, I'd love concrete feedback /issues.",
              "author": "eigen-vector",
              "depth": 1
            },
            {
              "text": "The keyword here is \"built\". I find when people use that, instead of \"wrote\", it's just AI slop.\nThat only works if there's a sliver of honesty left though.",
              "author": "the_biot",
              "depth": 1
            },
            {
              "text": "I like using put together a program, that sounds just about right for our current AI Overlords",
              "author": "jetbalsa",
              "depth": 2
            }
          ]
        },
        {
          "top": "Regardless of the result of the TUI - I'd try this out just because you found the perfect name. Well done!",
          "author": "denysvitali",
          "replies": [
            {
              "text": "thank you :) I would be lying if I said the name wasn't the spark. The project lives to serve the name.",
              "author": "eigen-vector",
              "depth": 1
            }
          ]
        },
        {
          "top": "Great idea, would it be possible to make it possible to add my own custom tshark one liners under weird stuff? For example, sometimes I find myself troubleshooting TCP retransmission issues that is specific to proprietary applications and that may not be relevant everyone else to have by default.\nAs an aside, I was thinking about something similar to this tool for a while now after seeing this post (\nhttps://news.ycombinator.com/item?id=46723990\n) where someone was using Claude to troubleshoot a PCAP. It made me think that it would be nice just to have a nice collection of tshark one-liners to quickly weed out any weird stuff right off the bat. I would assume that it would be a lot more performant than using a LLM and more scalable if you have large PCAP files.",
          "author": "Bluecobra",
          "replies": [
            {
              "text": "absolutely. May be the best way to do this would be some kind of a recipe store where the user can run (we can fuzzy match?) tshark oneliners. I'd love your thoughts on what the easiest/quickest integration would be.",
              "author": "eigen-vector",
              "depth": 1
            }
          ]
        }
      ]
    },
    {
      "id": "47143755",
      "title": "Show HN: Moonshine Open-Weights STT models – higher accuracy than WhisperLargev3",
      "link": "https://github.com/moonshine-ai/moonshine",
      "domain": "github.com",
      "author": "petewarden",
      "score": 135,
      "comment_count": 23,
      "created_ts": 1771970047,
      "is_internal": false,
      "post_text": "I wanted to share our new speech to text model, and the library to use them effectively. We&#x27;re a small startup (six people, sub-$100k monthly GPU budget) so I&#x27;m proud of the work the team has done to create streaming STT models with lower word-error rates than OpenAI&#x27;s largest Whisper model. Admittedly Large v3 is a couple of years old, but we&#x27;re near the top the HF OpenASR leaderboard, even up against Nvidia&#x27;s Parakeet family. Anyway, I&#x27;d love to get feedback on the models and software, and hear about what people might build with it.",
      "is_ask_hn": false,
      "matched_keywords": [
        "team",
        "startup",
        "feedback"
      ],
      "comments": [
        {
          "top": "According to the OpenASR Leaderboard [1], looks like Parakeet V2/V3 and Canary-Qwen (a Qwen finetune) handily beat Moonshine. All 3 models are open, but Parakeet is the smallest of the 3. I use Parakeet V3 with Handy and it works great locally for me.\n[1]: \nhttps://huggingface.co/spaces/hf-audio/open_asr_leaderboard",
          "author": "Karrot_Kream",
          "replies": [
            {
              "text": "By the way, I've been using a Whisper model, specifically WhisperX, to do all my work, and for whatever reason I just simply was not familiar with the Handy app. I've now downloaded and used it, and what a great suggestion. Thank you for putting it here, along with the direct link to the leaderboard.\nI can tell that this is now definitely going to be my go-to model and app on all my clients.",
              "author": "theologic",
              "depth": 1
            },
            {
              "text": "How much VRAM does parakeet take for you? For some reason it takes 4GB+ for me using the onyx version even though it’s 600M parameters",
              "author": "syntaxing",
              "depth": 1
            },
            {
              "text": "Parakeet V3 is over twice the parameter count of Moonshine Medium (600m vs 245m), so it's not an apples to apples comparison.\nI'm actually a little surprised they haven't added model size to that chart.",
              "author": "reitzensteinm",
              "depth": 1
            },
            {
              "text": "why V3 over V2 (assuming English only)?",
              "author": "tomr75",
              "depth": 1
            }
          ]
        },
        {
          "top": "I've helped many Twitch streamers set up \nhttps://github.com/royshil/obs-localvocal\n to plug transcription & translation into their streams, mainly for German audio to English subtitles.\nI'd love a faster and more accurate option than Whisper, but streamers need something off-the-shelf they can install in their pipeline, like an OBS plugin which can just grab the audio from their OBS audio sources.\nI see a couple obvious problems: this doesn't seem to support translation which is unfortunate, that's pretty key for this usecase. Also it only supports one language at a time, which is problematic with how streamers will frequently code-switch while talking to their chat in different languages or on Discord with their gameplay partners. Maybe such a plugin would be able to detect which language is spoken and route to one or the other model as needed?",
          "author": "francislavoie",
          "replies": []
        },
        {
          "top": "Any plans regarding JavaScript support in the browser?\nThere was an issue with a demo but it's missing now. I can't recall for sure but I think I got it working locally myself too but then found it broke unexpectedly and I didn't manage to find out why.",
          "author": "nmstoker",
          "replies": []
        },
        {
          "top": "Accuracy is often presumed to be english, which is fine, but it's a vague thing to say \"higher\" because does it mean higher in English only? Higher in some subset of languages? Which ones?\nThe minimum useful data for this stuff is a small table of language | WER for dataset",
          "author": "fareesh",
          "replies": []
        },
        {
          "top": "Very cool. Anyway to run this in Web assembly, I have a project in mind",
          "author": "999900000999",
          "replies": []
        }
      ]
    },
    {
      "id": "47140322",
      "title": "Show HN: Emdash – Open-source agentic development environment",
      "link": "https://github.com/generalaction/emdash",
      "domain": "github.com",
      "author": "onecommit",
      "score": 116,
      "comment_count": 47,
      "created_ts": 1771956037,
      "is_internal": false,
      "post_text": "Hey HN! We’re Arne and Raban, the founders of Emdash (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;generalaction&#x2F;emdash\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;generalaction&#x2F;emdash</a>).<p>Emdash is an open-source and provider-agnostic desktop app that lets you run multiple coding agents in parallel, each isolated in its own git worktree, either locally or over SSH on a remote machine. We call it an Agentic Development Environment (ADE).<p>You can see a 1 minute demo here: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;X31nK-zlzKo\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;X31nK-zlzKo</a><p>We are building Emdash for ourselves. While working on a cap-table management application (think Stripe Atlas + Pulley), we found our development workflow to be messy: lots of terminals, lots of branches, and too much time spent waiting on Codex.<p>Emdash puts the terminal at the center and makes it easy to run multiple agents at once. Each agent runs as a task in its own git worktree. You can start one or a few agents on the same problem, test, and review.<p>Emdash works over SSH so you can run agents where your code lives and keep the parallel workflow. You can assign tickets to agents, edit files manually, and review changes.<p>We also spent time making task startup fast. Each task can be created in a worktree, and creating worktrees on demand was taking 5s+ in some cases. We now keep a small reserve of worktrees in the background and let a new task claim one instantly. That brought task start time down to ~500–1000ms depending on the provider. We also spawn the shell directly and avoid loading the shell environments on startup.<p>We believe using the providers’ native CLIs is the right approach. It gives you the full capabilities of each agent, always. If a provider starts supporting plan mode, we don&#x27;t have to add that first.<p>We support 21 coding agent CLIs today, including Claude Code, Codex, Gemini, Droid, Amp, Codebuff, and more. We auto-detect what you have installed and we’re provider-agnostic by design. If there’s a provider you want that we don’t support yet, we can add it. We believe that in the future, some agents will be better suited for task X and others for task Y. Codex, Claude Code, and Gemini all have fans. We want to be agnostic and enable individuals and teams to freely switch between them.<p>Beyond orchestration, we try to pull most of the development loop into Emdash. You can review diffs, commit, open PRs, see CI&#x2F;CD checks, and merge directly from Emdash once checks pass. When starting a task, you can pass issues from Linear, GitHub, and Jira to an agent. We also support convenience variables and lifecycle scripts so it’s easy to allocate ports and test changes.<p>Emdash is fully open-source and MIT-licensed.<p>Download for macOS, Linux or Windows (as of yesterday !), or install via Homebrew: brew install --cask emdash.<p>We’d love your feedback. How does your coding agent development setup look like, especially when working with multiple agents? We would want to learn more about it. Check out our repository here: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;generalaction&#x2F;emdash\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;generalaction&#x2F;emdash</a><p>We’ll be around in the comments — thanks!",
      "is_ask_hn": false,
      "matched_keywords": [
        "feedback",
        "remote",
        "startup",
        "management"
      ],
      "comments": [
        {
          "top": "Here's my question:\nif agents continue to get better with RL, what is future proof about this environment or UI?\nI think we all know that managing 5-10 agents ... is not pretty. Are we really landing good PRs with 100% cognitive focus from 5-10 agents? Chances are, I'm making mistakes (and I assume other humans are too)? Why not 1 agent managing 5-10 agents for you? And so on?\nMost of the development loop is in bash ... so as long as agents get better at using bash (amongst other things), what happens to this in 6 months?\nI don't think this is operating at a higher-level of abstraction if agents themselves can coordinate agents across worktrees, etc.",
          "author": "mccoyb",
          "replies": [
            {
              "text": "Interesting thoughts - thank you! And directionally agree - given that agents are becoming ever better, they'll take more and more of the orchestration on themselves. Still, we believe that developers need an interface to interact with these agents; see their status and review / test their work. Emdash is our approach for building this interface of the future - the ADE :)",
              "author": "onecommit",
              "depth": 1
            },
            {
              "text": "> Still, we believe that developers need an interface to interact with these agents;\nCLIs like claude code equally improve over time. tmux helps running remote sessions like there were local.\nWhy should we invest long time into your „ADE“, really?\n> see their status and review / test their work\nWon’t that be addressed eventually by the CLIs themselves?\nMaybe you’re betting on being purchased by one of the agentic coding providers given your tool has long term value on its own?",
              "author": "blumomo",
              "depth": 2
            },
            {
              "text": "People use UIs for git despite it working so well in the terminal... Many people I knew at uni doing computer science wouldn’t even know what tmux is. I would bet that the demand for these types of UIs is going to be a lot bigger than the demand for CLI tools like Claude Code. People already rave about cowork and the new codex UI. This falls into the same category.",
              "author": "sothatsit",
              "depth": 3
            }
          ]
        },
        {
          "top": "We are experimenting with this kind of development style and from my experience so far this shift a lot of the complexity of building into the story writing and manual testing phases.\nAs I will need to fully handover the task and let the agent(s) essentially one-shot the implementation I need to be way for specific and clear in giving it context and goals, otherwise I’m afraid it will start build code purely by accumulation creating a pile of unmanageable garbage.\nAlso changes which requires new UI components tend to require more manual adjustments and detailed testing on the UX and general level of polishing of the experience our users expect at this stage.\nI’m starting to develop a feeling of tasks that can be done this way and I think those more or less represent 20 to 30% of the tasks in a normal sprint. The other 70% will have diminishing returns if not actually a negative return as I will need to familiarise with the code before being able to instruct AI to improve/fix it.\nFrom your experience building this, what’s your take on:\n1. How do your product helps in reducing the project management/requirements gathering for each individual tasks to be completed with a sufficient level of accuracy?\n2. Your strong point seems to be in parallelisation, but considering my previous analysis I don’t see how this is a real pain for a small teams. Is this intended to be more of a tool for scale up with a stable product mostly in maintenance/enhancement mode?\n3. Are you imagining a way for this tool to implement some kind of automated way of actually e2e test the code of each task?",
          "author": "nerder92",
          "replies": [
            {
              "text": "Thanks! What tools have you been experimenting with?\nAgreed. That this evolution pushes much of the work into describing desired outcomes and giving sufficient context.\nTo your questions:\nEmdash helps reduce the setup cost of each environment by allowing you to open an isolated git worktree, copying over env variables and other desired context. And then preserving your conversation per task. That said, you still need to write clear goals and point it in the right direction.\nI think it's less about team scale and more about individual throughput. My working mode is that I'm actively working on one or two tasks, switching between them as one runs. Then I have a long list of open tasks in the sidebar that are more explorative, quick reviews, issue creation etc. So for me it's not about one-shotting tasks, but instead about navigating between them easily as they're progressing\nAutomated e2e testing is tricky, particularly for rendering. I think roborev (\nhttps://github.com/roborev-dev/roborev\n) is moving in the right direction. Generating bug reports synchronously per commit and not just once you create a PR. I also think what \nhttps://cursor.com\n shipped today with computer-use agents testing interfaces is very interesting.",
              "author": "onecommit",
              "depth": 1
            }
          ]
        },
        {
          "top": "So, what's your business model ? Is this an YC product, or a tool you developed while working on a YC product ?",
          "author": "ttoinou",
          "replies": [
            {
              "text": "We're figuring our business model out. There're two avenues that we principally think about (1) bundled coding agent subscription and (2)enterprise version with auth, team management, sharing of agent interactions. Admittedly, it's early and this can change. What won't change is that this UI layer for running multiple coding agents is and will be open-source. Emdash itself is funded by YC. Initially developed as a tool while working on another product, but we weren't funded then.",
              "author": "onecommit",
              "depth": 1
            },
            {
              "text": "(2) sounds like a great idea if you can ensure private company data never reaches your servers, with features like remote controlling agents from a central place",
              "author": "ttoinou",
              "depth": 2
            },
            {
              "text": "Thank you, and yes!",
              "author": "onecommit",
              "depth": 3
            }
          ]
        },
        {
          "top": "Been driving my agents (CC, currently testing Pi) for a couple of weeks via Emdash. Finally, got a productive worktree setup working. There were still rough edges when I started, but the team has shipping fast [0] and is vaporizing concerns on the fly. Building on top of the native CLI seems to be the right strategy as well.\n[0] \nhttps://github.com/generalaction/emdash/releases/",
          "author": "haimau",
          "replies": []
        },
        {
          "top": "Wild how quickly developer workflows change. I went from cursor -> claude code CLI -> emdash (mix of claude code and codex now)",
          "author": "ck_one",
          "replies": []
        }
      ]
    },
    {
      "id": "47140133",
      "title": "1Password Raising Prices ~33%",
      "link": "https://news.ycombinator.com/item?id=47140133",
      "domain": "news.ycombinator.com",
      "author": "iamben",
      "score": 82,
      "comment_count": 46,
      "created_ts": 1771955276,
      "is_internal": true,
      "post_text": "Email today:<p>Since 2005, 1Password has been on a mission to make security simple, reliable, and accessible for everyone. As the way people work and live online has evolved, so has 1Password.<p>More recently, we’ve invested significantly in new features that make 1Password even more powerful and effortless to use, helping protect what matters most to you, including:<p>- Automatic saving of logins and payment details\n- Enhanced Watchtower alerts\n- Faster, more secure device setup\n- AI-powered item naming\n- Expanded recovery options\n- Proactive phishing prevention<p>While 1Password has grown substantially in value and capability, our pricing has remained largely unchanged for many years. To continue investing in innovation and the world-class security you expect, we’re updating pricing for Individual plans, starting March 27, 2026.<p>Current vs New Pricing:<p>Current price: $35.88 USD &#x2F; year\nNew price: $47.88 USD &#x2F; year<p>The new price will take effect at your next renewal, provided it’s on or after March 27, 2026. Those occurring prior to March 27, 2026, will continue at the current pricing until your next renewal.<p>If you have any questions, please reach out to support by replying to this email. We’re deeply grateful for your continued trust and support.<p>Thank you,\nThe 1Password Team",
      "is_ask_hn": false,
      "matched_keywords": [
        "team"
      ],
      "comments": [
        {
          "top": "My family pricing went up by 20%, from $59.88 USD to $71.88 per year.\nI like 1Password a lot. I've used it for 10 years. It's never lost a single thing, and I don't recall any downtime that impacted me. It's easy to setup and 99% hassle free. Works on my various device types (windows, mac, ios). It supports passkeys and 2FA codes. I like having shared and private vaults. I love the ability to share an auto-expiring, one-time-view link to a password. And the billing is a simple subscription fee.\nI could do without some bloat. Watchtower feels like an enterprise need that is otherwise low-value and (by default) noisy for individuals/families. I obviously don't need \"AI\" forced into my password manager. I didn't love the version 7 to 8 transition that required a new app/extension to be installed. But all of that is really not so bad.\nSo yeah, I don't feel like I'm getting any additional value that justifies the price increase, but it's still more than worth it for me.",
          "author": "quacker",
          "replies": [
            {
              "text": "You mean they didn't increase prices in 10 years? A 2016 dollar is not the same thing as a 2026 dollar",
              "author": "Valodim",
              "depth": 1
            },
            {
              "text": "Oh true. Considering inflation, $60 in 2016 is about $80 in 2026 so really the price has gone down in real terms.\n(Not actually sure about the price history of the family plan or when family was introduced. I was originally on the individual plan and it was $35 then, and switched to the family plan in 2022. I don’t think prices have changed though)",
              "author": "quacker",
              "depth": 2
            }
          ]
        },
        {
          "top": "I get a lot of value from 1Password but the software quality has fallen.\nThere was a period of time that 1P would constantly grab window focus on macOS, they must have finally fixed it because after months of it randomly happening I don't think it's happened for at least 4 months. Then there is stuff like adding a new item, the search \"Try searching anything\", well, at least as long as \"Anything\" is not the _type_ of new item you want to create...\nIf I search \"API\" because I want to create an API key entry it shows be a bunch of worthless suggestions of websites (why would that be useful?) and at the bottom just injects my search term into the name of the 3 top \"types\" of item you can make. I have to expand it and scroll down to find API Credential. This is maddening to me. In part because of the mocking \"Try searching anything\", which is just clearly BS, and in part because I find the website search 100% useless and the only thing I care to search on is the types of new 1Password item I might create.\nVideo: \nhttps://cs.joshstrange.com/jFqYXC8q",
          "author": "joshstrange",
          "replies": []
        },
        {
          "top": "Completely worth it to me.  It would be an incredible value at twice the price and part of my daily workflow on all machines.",
          "author": "morgango",
          "replies": [
            {
              "text": "Same, just excellent software that I use 100+ times per day.\nQuality matters in what you use constantly.",
              "author": "don_neufeld",
              "depth": 1
            },
            {
              "text": "100+ times a day? Explain yourself.\nI login/unlock my password manager maybe...a dozen times a week and that would be a high count when I'm doing \"business\" and logging in for financial things.",
              "author": "mcsniff",
              "depth": 2
            },
            {
              "text": "+1\nFor pure peace-of-mind managing a family and all our passwords and digtial security, it's value is far more than this monthly cost",
              "author": "oliyoung",
              "depth": 1
            }
          ]
        },
        {
          "top": "I've had good experiences with KeePassXC. In addition to being able to store your passwords, it can ingest TOTP seeds. And finally, it's open source and cross platform. (I originally stumbled upon it because it was the only KeePass implementation that tried to look like a native MacOS app)\nThis is a killer feature for me, since apparently iOS backups do not backup your TOTP generators in Google Authenticator, which I discovered after I wiped my phone and restored it thinking I was perfectly safe doing so given I had a backup.\nI now encourage all the folks I mentor to set up a KeePass vault for the TOTP seeds.\nThere's even an option to generate one of those fancy QR codes that apps like authenticator can use, so the two are not mutually exclusive.\nIf you're an individual, not an enterprise user, I don't see why anyone would pay for a password manager.",
          "author": "firefax",
          "replies": [
            {
              "text": "Is KeePassXC better than Bitwarden?",
              "author": "JavaWing",
              "depth": 1
            },
            {
              "text": "I use both (for different purposes) and prefer the native app (and KeePassDX on Android), but note that it is a local app and doesn't sync. You need to use something else (eg. Syncthing or Dropbox) for that.",
              "author": "rlpb",
              "depth": 2
            }
          ]
        },
        {
          "top": "A very recent frustration from them was this: \nhttps://x.com/youyuxi/status/2005904473332564339?s=20\n - their Chrome extension was breaking code block rendering on a lot of websites for weeks. \nThe issue had already been reported in their community forum, but it didn’t seem to gain much traction until Evan You mentioned it publicly on Twitter. Only then did it feel like it was taken seriously.\nThat experience, combined with a ~33% price increase, makes the direction a bit concerning, and feels like it’s going in a down hill...\nThat said, it’s genuinely difficult to move my family off 1Password. I just wish there are stronger competitors.",
          "author": "imfing",
          "replies": [
            {
              "text": "Their Linux app crashes half the time trying to launch, and I have to resort to the browser app. It's been like this for at least the 1 year I've been a customer. And, Their browser app also has a horrendous impact on browser performance. I always thought Firefox was just kind of slow..but it was 1password bogging it down all along.",
              "author": "daringrain32781",
              "depth": 1
            }
          ]
        }
      ]
    },
    {
      "id": "47117946",
      "title": "What I learned designing a barebones UI engine",
      "link": "https://madebymohammed.com/miniui",
      "domain": "madebymohammed.com",
      "author": "teleforce",
      "score": 80,
      "comment_count": 42,
      "created_ts": 1771819309,
      "is_internal": false,
      "post_text": "",
      "is_ask_hn": false,
      "matched_keywords": [
        "learned"
      ],
      "comments": [
        {
          "top": "> While it’s far from perfect, writing it taught me more about UI systems than I ever would have learned by sticking to established solutions alone.\nThis is a great attitude to have. Keep up the great work.",
          "author": "dazzawazza",
          "replies": []
        },
        {
          "top": "Immediate mode GUI is the way to go.\nRetaining state is a pain and causes bugs. Trying to get fancy a la react and diffing the tree for changes makes not sense. That was a performance hack because changing the DOM in JS used to be slow as hell. You don't need that.\nJust redraw the whole thing every frame. Great performance, simple, less bugs.",
          "author": "cardanome",
          "replies": [
            {
              "text": "This works for simple apps, utilities, and demos/mvps. Not great for actual applications.\nWhat about when you're embedding your GUI into an existing application? or for use on an already taxed system? (Audio plugins come to mind)\nWhat if something is costly, that you need to compute dynamically, but not often, makes it into the frame? Do you separately now create a state flag for that one render object?",
              "author": "tarnith",
              "depth": 1
            },
            {
              "text": "> What if something is costly, that you need to compute dynamically, but not often, makes it into the frame? Do you separately now create a state flag for that one render object?\nThe point of immediate mode UIs is not necessarily that there is no state specific to the UI, but rather that the state is owned by user code. You can (and, in these more complex cases, should) retain state between frames. The main difference is that the state is still managed by your code, rather than the UI system (\"library\", whatever).",
              "author": "spiffyk",
              "depth": 2
            },
            {
              "text": "Immediate mode UI optimizes for the worst case. That is the case you care about most for real time applications.\nRetained mode is more optimal when not much changes but if a lot of stuff changes at once it can be worse. So for real time applications like your audio example or games you want immediate mode. Retained mode is better for saving battery though or can be.",
              "author": "cardanome",
              "depth": 2
            },
            {
              "text": "> What about when you're embedding your GUI into an existing application? or for use on an already taxed system?\nYou should check out the gamedev scene. It's soft real-time, and yet dearIMGUI is the choice for tooling. Immediate-mode is an API-design, not the implementation details. All Immediate-mode GUIs retain data some data, and for that reason they each have their own APIs for retaining data in various capacities. Usually something really simple like hashing and component-local state.\n> This works for simple apps, utilities, and demos/mvps. Not great for actual applications.\nRespectfully, I don't think you're informed on this. Probably the most responsive debugger out there is RAD Debugger and it's built with an IMGUI.",
              "author": "leecommamichael",
              "depth": 2
            },
            {
              "text": "For interest sake, have a look at the flutter engine. It does this kind of diff on each build (meaning, each time the ui tree gets modified & triggers a rebuild); they split their objects into stateful & stateless, and then in your own code you have to make sure to not unnecessarily trigger rebuilds for expensive objects. So it kinda force you to think & separate cheap & expensive ui objects.",
              "author": "BatteryMountain",
              "depth": 2
            }
          ]
        },
        {
          "top": "Had a similar itch during my game development with libgdx, and had almost same architecture eventually\nI found that I have two different ways to construct UI layout , from top down, and from down to top, those could be contradictory, wonder how one could solve this, seems like common problem in all frameworks that I saw, like flutter just fail with error on screen if it can't solve restrictions in such conflict , others just show jiberish",
          "author": "threetwoonezero",
          "replies": []
        },
        {
          "top": "author here - thanks for posting :D\nwould love to hear any thoughts or questions.",
          "author": "mbmproductions",
          "replies": [
            {
              "text": "At what point do you think you’d give in and use an existing solution?\nI’m going through similar “hell” (my words). I just wanted some simple Ui for WebXR but the dipshits that designed XR for the web fucking threw all the web parts out so you can not just put up a few simple html elements up in XR. You have to write your own UI library from scratch. It’s so mind bogglingly stupid.\nIn any case, having to write it, like you I started small and the it quickly ballooned because even simple things get complicated quickly, all the while I’m cursing under my breath there is a perfectly unable system but TPTB chose not to offer it >:(",
              "author": "socalgal2",
              "depth": 1
            },
            {
              "text": "existing solutions for my specific use case were limited, i intentionally wanted something barebones so that I could hack at the raw surfaces / display buffers to cut corners for performance. one part learning experience, one part stubbornness.\nWebXR sounds like a different beast entirely. do you have to write your own rendering backend in WebGL for that?",
              "author": "mbmproductions",
              "depth": 2
            },
            {
              "text": "Webgl or webgpu, but for ui you can just draw to a canvas and copy that canvas into webgl/webgpu. That means you can easily iterate on the ui system in 2d with mouse input similar to what you’ve been doing in python\nBut, as an example of similar complexity. I hacked together the first Ui I needed. It was 6 buttons and a slider. Then I realized I needed two more Ui panels and started to write more real Ui classes to abstract stuff out and, it just starts getting more and more complicated.\nA slider needs to “capture the pointer”, meaning as you drag it, if to drag past the end of the slider and the pointer is now over another widget the events should still go to the slider. It’s not hard to implement, it’s just frustrating for me that I don’t actually want to write it. I just want to make my panel and if I could just use html id be done. Instead I’m spending my limited free time making this ui system. I don’t have that much and would be much further along in my actual goals except for this road block",
              "author": "socalgal2",
              "depth": 3
            },
            {
              "text": "Looks really cool. Thank you for sharing!",
              "author": "selridge",
              "depth": 1
            }
          ]
        },
        {
          "top": "> writing it taught me more about UI systems than I ever would have learned by sticking to established solutions alone\nBut less if you had spent a fraction of that time just learning about established solutions and hacking around those\n(ironic indicator: the first button on the page reflows on first click, so an example of bad UI)",
          "author": "eviks",
          "replies": []
        }
      ]
    },
    {
      "id": "47113936",
      "title": "Ask HN: Chromebook leads for K-8 school in need?",
      "link": "https://news.ycombinator.com/item?id=47113936",
      "domain": "news.ycombinator.com",
      "author": "techteach00",
      "score": 45,
      "comment_count": 43,
      "created_ts": 1771789167,
      "is_internal": true,
      "post_text": "Hi, I&#x27;m a K-8 technology teacher in NYC. My students are in desperate need of new hardware. The Chromebooks they use now are so slow that they make the children agitated when using them.<p>I&#x27;m aware of different grant opportunities that exist, I just thought it was worth inquiring here for a potentially faster solution at acquiring them new hardware.<p>Thank you for listening.",
      "is_ask_hn": true,
      "matched_keywords": [],
      "comments": [
        {
          "top": "Relevant recent publication about laptops and students:\nhttps://fortune.com/2026/02/21/laptops-tablets-schools-gen-z...\nBut I get it OP, you work with what you're given. I'm sorry I don't have any good suggestions.",
          "author": "notepad0x90",
          "replies": [
            {
              "text": "As a former student using Chomebooks in Highschool (9-12), a K-8 laptop is a major “ew”. Paper textbooks have tactile reality, room for exploring/reading out of order. Paper exams you can skip around the questions easily, and if the teachers are really that backed up to grade them, good ole’ scantrons are doable. An assigned laptop has 0 attachment from the students and just get neglected to pieces, and no one is “learning computer skills” by clicking around Canvas lectures.",
              "author": "TheJoeMan",
              "depth": 1
            },
            {
              "text": "They could have gone with non-networked ereaders. But they just had to go with the \"smart\" and \"connected\" angle so they could do grading, spying on kids,etc.. similar to the current \"AI\" approach. scope-creep. but even with ereaders, being able to switch to different books easily is an impediment, or having access to too many at one time. Physical books force a certain focus and attention.\nYour point about tactility is solid too. flipping through pages is very different from swiping. With educational textbooks, you'd have to look at multiple pages at the same time (flipping back and forth quickly) to connect and understand a topic by referencing another topic. Same with being able to easily lay out multiple physical books in front of you.",
              "author": "notepad0x90",
              "depth": 2
            }
          ]
        },
        {
          "top": "Thank you for the suggestions.\nI think I realize the problem after reading many of the posts. What's slowing these devices down is the management software running over them. GoGuardian and whatever else IT has on them.\nWe also aren't allowed to use an ad blocker anymore. I used to have Ublock installed on all the devices before GoGuardian prevented it. It's a really depressing situation that I imagine will only get worse with time.\nAs to a few replies asking why students in this age group would need laptops, I'll explain. I start teaching Python in 6th grade. Grades 3-5 use Scratch. Grade 2 uses code.org. K-1 Scratch Jr on Ipads.\nWe have expensive mac desktops in the computer lab but they drive the students completely insane for two reasons. The keyboard is and mouse are terrible to use. Anti-ergonomic. The second reason is the amount of notifications and questions the students are bombarded with when they turn the macs on. I'm talking like 15 different pop ups or windows opening asking them to agree to this or that. I should probably have a lesson on just closing windows. I could say more but I don't know about social media anymore. I just wanted some suggestions and I appreciate the ones I received.",
          "author": "techteach00",
          "replies": [
            {
              "text": "You should open the issue with your IT department and see if they can optimize the performance. You can gather proof that GoGuardian is causing slow downs by looking at it's memory usage in the Task Manager (right click empty area in Chrome tab bar).",
              "author": "cloudking",
              "depth": 1
            }
          ]
        },
        {
          "top": "https://chromeos.google/products/chromeos-flex/\n1. Find older Intel Core Based Windows Laptops (at least 6GB of RAM)\n2. Put ChromeOS Flex on them\n3. Students will be sad it is still ChromeOS, but they will be happy it is like 3x faster.\nI had an old Windows laptop laying around and I did this for my 80 yr old parents and they were super happy.",
          "author": "manjose2018",
          "replies": [
            {
              "text": "This. Especially lots of i5-6300U based corporate laptops like latitude are on eBay etc for < 100$",
              "author": "whyagaindavid",
              "depth": 1
            }
          ]
        },
        {
          "top": "If you haven't already looked into PCs for People, they might be a low-cost option for your school: \nhttps://www.pcsforpeople.org/tech-for-nonprofits/#Eligibilit...\nPCs for People is a non-profit organization whose mission is to bridge the digital divide (e.g. through sales of low-cost refurbished computers, internet access, and digital skills training).\nThey refurbish and sell computers to eligible organizations, including schools and offer bulk orders (6+ units) via email at \"partner [at] pcsforpeople [dot] org\".\nIf the order is 5 units and below, you use their publicly available online store link at pcsrefurbished.com/sales/salesHome.aspx",
          "author": "dugvuivnhuihnvu",
          "replies": []
        },
        {
          "top": "In New York the biggest driver behind technology is the state testing regime. Make the case to your administration that the chromebooks are insufficient for the state testing program and they will come up with the funds for upgrades.",
          "author": "dzdt",
          "replies": []
        }
      ]
    },
    {
      "id": "47085255",
      "title": "Ask HN: Is it worth learning Vim in 2026?",
      "link": "https://news.ycombinator.com/item?id=47085255",
      "domain": "news.ycombinator.com",
      "author": "zekejohn",
      "score": 35,
      "comment_count": 35,
      "created_ts": 1771576049,
      "is_internal": true,
      "post_text": "With everyone using Claude Code, Cursor, Codex, and the other 100 AI coding agents that i missed, I’m wondering how much editor mastery still matters like w&#x2F; Vim<p>Being honest the real reason i wanna learn Vim is to boost my ego &amp; assert my dominance, so i can tell people &quot;i use vim btw&quot;, but also part of me thinks investing time could still pay off for speed, ergonomics, and working over SSH overall...<p>but a bigger part also suspects the marginal gains i would gain would disappear when more of the work is delegated to AI anyway, like why would i learn Vim if i&#x27;m just going to be prompting Opus all day?<p>For anyone who&#x27;s been using Vim for while AND uses AI to code (i&#x27;m assuming everyone codes with AI to some degree) my question is: Does learning Vim still meaningfully improve your day to day productivity EVEN with AI, or is it mostly personal preference at this point?",
      "is_ask_hn": true,
      "matched_keywords": [],
      "comments": [
        {
          "top": "Do you already do any work over SSH? What do you do if you need to edit any files in that context?\nLearning the essentials of vim was the sort of skill that for me took about 10 min per day over a couple months and has come in handy almost every day since then. Can you get by without it? I guess, if you do absolutely everything via a GUI. Or delegate all CLI work to LLMs without ever questioning or second guessing their output.\nAnd yes, I use vim for almost every git commit or interactive rebase. Access to the full power of CLI git is something I value very much and has saved me countless hours.  Not to mention using it for editing any config file that’s not part of a repo.\nEvery time you’re able to keep your fingers on the keyboard instead of reaching for a mouse saves you both time and precious context switching energy.",
          "author": "apothegm",
          "replies": [
            {
              "text": "Aficionados of modal editing often insinuate that one would require mouse use in non-modal editing. Yet I have always fully keyboard-operated my non-modal editors, whether VSCode in the last 9 years or previously, Sublime and others, all the way back to Turbo Pascal in the late 90s. I don't ever use the mouse in them, whether I'm inside a text buffer or in the Command Palette (or in menus for the pre-Sublime editors back when). For example, F1 is bound to show \"hover\" doc tips over the symbol that the caret is in. A couple function keys and ctrl/alt/shift-plus-some-mnemonic letter are soo swiftly and easily muscle-memoried, I never felt any need for mousing, or for \"modes\" and typing just to switch from one to another.\nI'm sure once one is used to modal editing, one can be speedy with it. So can I, entirely without modal yet without mousing  =)",
              "author": "dualogy",
              "depth": 1
            },
            {
              "text": "I also use VSCode and derivatives. Also mostly without mousing. But I don’t HAVE to, because I know how to use CLI tooling to not only edit files as needed but also handle things like version control — which I’ve noticed a disappointing percentage of my colleagues, even those with a decade in the field, are mystified by. I haven’t touched VSCode’s git integrations, but the astonishment at being introduced to CLI rebasing — followed by interactive rebasing — was eye-opening.",
              "author": "apothegm",
              "depth": 2
            },
            {
              "text": "Well for git stuff or any CLI stuff, I just key-chord into the integrated terminal (or alt-tab into my terminal emulator, depending on task) and do the git commands, having the whole \"git integration\" thing disabled in `settings.json` in the first place..",
              "author": "dualogy",
              "depth": 3
            }
          ]
        },
        {
          "top": "Yes. For one simple reason: As vi is part of the POSIX standard[1], it is gauranteed to be installed on all unix(-like) machines you may touch now or in the future.\n[1] \nhttps://pubs.opengroup.org/onlinepubs/9699919799/",
          "author": "mmh0000",
          "replies": []
        },
        {
          "top": "It's a handy skill to have if you interact with Linux machines.\nYou'll need to edit files sometimes, and Vim (or Vi) is usually present. I don't think I've seen an install without it.\nThe basics (opening files, writing, and closing) can be learnt in an hour. It's enough to make simple changes to .conf files.",
          "author": "grugdev42",
          "replies": [
            {
              "text": "Using vim to do this seems silly. Nano is also nearly always present, and doing those “basic” things is 10x more straightforward in an editor that isn’t modal and just gets out of your way.\nI’ve often in my career witnessed engineers who’ve cargo culted the need for vim, but they only know how to hit ESC !wq or whatever, and one errant keystroke puts them in modal hell of some sort that, often requiring they just close the terminal and try again.\nI don’t begrudge those who want to become power-VIM-users, though it seems wildly awkward to me, to each their own. But if you just want to use it to do the “basics” on ssh sessions, using nano makes more sense. PGUP and PGDN and Home and End and arrows work just fine to navigate, and the bindings for most things are printed right on the screen (except Ctrl-S to save… for some reason, but it works).",
              "author": "xp84",
              "depth": 1
            }
          ]
        },
        {
          "top": "What happens if?\n1. The LLMs are down, and you're on call and you need to fix a bug \nimmediately\n (no mistakes)\n2. You're working over serial (The LLMs aren't there to help you and only vi and emacs are available)\n3. You're working on an old computer for some esoteric reason.\n4. You're going in an interview and they (temporarily) forbid you to use an LLM to check your knowledge on using these tools (as well as programming tests)\nIf you cannot use these editors without an LLM, (Vim has navigation keys 'hjkl', G/g and so forth which many such tools have adopted), then it isn't a good look.\nYou don't have to 100% master them but knowledge of them will help when the LLMs have an outage, and there WILL be outages.\nAlso be careful not to keep relying on these LLMs too much otherwise your programming skills will atrophy. [1]\nSo the answer is YES, learn Vim, not to boost your ego, but make it a muscle memory so your skills won't atrophy.\n[1] \nhttps://www.infoworld.com/article/4125231/ai-use-may-speed-c...",
          "author": "colesantiago",
          "replies": [
            {
              "text": "ya i do definitely agree that learning Vim is gonna help my overall understanding for how things work at a deeper level and also fight back a lot of the “learned helplessness” that i did develop when coding w/ AI to your point\n also another thing that i was thinking is that yes short term (maybe the first few months?) i wouldn’t see any benefit… but it would definitely help in the long term and that my coding ability is not just directly tied to whatever the latest model is capable of",
              "author": "zekejohn",
              "depth": 1
            },
            {
              "text": "Use emacs. Easier to learn.",
              "author": "ant6n",
              "depth": 1
            },
            {
              "text": "For some people cua-mode being opt-in and very difficult to discover organically will be a larger barrier for comfort and learning than normal/insert modes and motion commands could ever hope to be.\n(10 year evil-mode user who moved to Neovim for other reasons, chiefly performance/LSP nativity/plugin ecosystem vitality)",
              "author": "mtndew4brkfst",
              "depth": 2
            },
            {
              "text": "You just need learn C-x C-s (save) and C-x C-c (exit) to be able to edit files on the command line. It's kind of like nano, except has syntax highlighting.",
              "author": "ant6n",
              "depth": 3
            }
          ]
        },
        {
          "top": "Not everything in life is about being more productive.\nI think it’s worth learning vim, or emacs shortcuts, as an intellectual exercise.\nI still save time by editing little code thanks to vim, or vim mode in my ide. And it doesn’t take that long to know the basics. Is it worth it in terms of seconds saved over a career? Perhaps not anymore.",
          "author": "speedgoose",
          "replies": []
        }
      ]
    },
    {
      "id": "47127532",
      "title": "Ask HN: How do you know if AI agents will choose your tool?",
      "link": "https://news.ycombinator.com/item?id=47127532",
      "domain": "news.ycombinator.com",
      "author": "dmpyatyi",
      "score": 29,
      "comment_count": 22,
      "created_ts": 1771875121,
      "is_internal": true,
      "post_text": "YC recently put out a video about the agent economy - the idea that \nagents are becoming autonomous economic actors, choosing tools and \nservices without human input.<p>It got me thinking: how do you actually optimize for agent discovery? \nWith humans you can do SEO, copywriting, word of mouth. But an agent \njust looks at available tools in context and picks one based on the \ndescription, schema, examples.<p>Has anyone experimented with this? Does better documentation \nmeasurably increase how often agents call your tool? Does the \nwording of your tool description matter across different models \n(ZLM vs Claude vs Gemini)?",
      "is_ask_hn": true,
      "matched_keywords": [],
      "comments": [
        {
          "top": "Experimented with this a lot while building agent tooling.\nThe short answer: yes, description wording measurably matters, and it's more sensitive than most people expect.\nA few things we've found that move the needle:\n1. Concrete use-case beats generic label. 'Send a transactional email after payment confirmation' outperforms 'Send email' by a wide margin across models — the agent doesn't have to infer when to use it.\n2. Negative constraints help. Explicitly saying 'Don't use this for bulk sends or newsletters' actually reduces hallucinated misuse, because the model has a clear mental model of the boundary.\n3. Schema field names are silent prompts. A field named 'recipient_email' gets filled correctly far more than 're' or even 'to'. The model is pattern-matching on names it's seen in similar contexts.\n4. Example I/O beats description prose. If you include one example input and what the output looks like, agents are significantly more likely to call the tool correctly on the first attempt.\nFor cross-model consistency: Claude tends to do better with structured JSON schema + examples. GPT-4 responds well to prose descriptions with analogies. Gemini seems to weight field name patterns heavily.\nThe broader pattern: treat your tool description like a micro few-shot prompt, not an API doc. Optimize for the model's context, not for human readers.",
          "author": "MidasTools",
          "replies": []
        },
        {
          "top": "We've been exposing tools via MCP and the biggest lesson so far: the tool description is basically a meta tag. It's the only thing the model reads before deciding whether to call your tool.\nTwo things that surprised us: (1) being explicit about what the tool doesn't do matters as much as what it does - vague descriptions get hallucinated calls constantly, and (2) inline examples in the description beat external documentation every time. The agent won't browse to your docs page.\nThe schema side matters too - clean parameter names, sensible defaults, clear required vs optional. It's basically UX design for machines rather than humans. Different models do have different calling patterns (Claude is more conservative, will ask before guessing; others just fire and hope) so your descriptions need to work for both styles.",
          "author": "jackfranklyn",
          "replies": [
            {
              "text": "*Clean parameter names, sensible defaults, clear required vs optional. It's basically UX design for machines rather than humans.*\nBut it's the same points you should follow when designing a human readable docs(as zahlman said above). Isn't it?",
              "author": "dmpyatyi",
              "depth": 1
            },
            {
              "text": "> inline examples in the description beat external documentation every time. The agent won't browse to your docs page.\nThat seems... surprising, and if necessary something that could easily be corrected on the harness side.\n> The schema side matters too - clean parameter names, sensible defaults, clear required vs optional. It's basically UX design for machines rather than humans.\nI don't follow. Wouldn't you do all those things to design for humans anyway?",
              "author": "zahlman",
              "depth": 1
            }
          ]
        },
        {
          "top": "From building in this space: agents choose tools based on how well they're described in context, not on brand recognition or marketing.\nPractically: the agent reads your docs, README, or API description and decides if it can use your tool to solve the current problem. So the question is really \"will an AI \nunderstand\n my tool well enough to use it correctly?\"\nWhat helps: \n- Clear, literal API documentation (not marketing copy)\n- Explicit input/output examples with edge cases\n- A `capabilities.md` or similar that describes what the tool does and doesn't do\nThe irony: the skills that make tools understandable to AI (precision, literalness, examples) are the opposite of what makes them legible to humans (narrative, benefits, stories).",
          "author": "MidasTools",
          "replies": [
            {
              "text": "Is there are some additional tool/service/instrument that can measure it?\nI mean how do i check that my changes in documentation even work in a right way?",
              "author": "fenix1851",
              "depth": 1
            }
          ]
        },
        {
          "top": "I run a multi-agent orchestration system where each terminal has access to skill templates. The orchestrator (T0) picks which skill to assign based on the task — so I've spent months tuning how skill descriptions affect agent behavior.\nWhat I found: the description is the entire selection surface. The agent doesn't read your code, doesn't check your tests, doesn't browse your docs. It reads the description and decides in one pass.\nThree things that actually moved the needle:\nNegative boundaries work better than positive claims. \"Generates reports from structured receipts. Does NOT execute code, modify files, or make API calls\" gets called correctly way more often than \"A powerful report generation tool.\"\nTrigger words matter more than you'd think. I maintain explicit trigger lists per skill — specific phrases that should activate it. Without those, the agent pattern-matches on vibes and gets it wrong ~30% of the time. With explicit triggers, that drops to under 5%.\nSchema is the real interface. Clean parameter names with sensible defaults beat elaborate descriptions. If your tool takes query: string vs search_query_input_text: string, the first one gets called more reliably across models.\nBut here's the thing the \"agent economy\" framing gets wrong: you don't want fully autonomous tool selection. An agent choosing freely between 50 tools is like giving a junior developer admin access to everything — it'll work sometimes and break spectacularly other times. What works better is constraining the agent's scope upfront. Give it 3-5 relevant skills for the task, not your entire toolkit. Or build workflow skills that chain multiple tools in a fixed sequence — the agent handles the content, the workflow handles the routing.\nThe uncomfortable truth: you're not optimizing for \"discovery\" in the human sense. There's no brand loyalty, no trust built over time. Every single invocation is a cold start where the model reads your description and decides. That's actually freeing — it means the best-described tool wins, regardless of who built it.",
          "author": "vincentvandeth",
          "replies": [
            {
              "text": "One thing I’ve noticed is that as my context grows, often performance degrades. So how are you battling your agents being exposed to too many descriptions? I how this works in curated agents where you’re tending it like a garden, but not when we’re looking for organic discovery of how to accomplish a task. It feels like order matters a lot there.",
              "author": "wolftickets",
              "depth": 1
            },
            {
              "text": "Context bloat is a real problem — and yes, order matters more than most people realize. Descriptions near the top of the tool list get preferentially selected, especially in long contexts where attention degrades.\nTwo things I do to fight this:\nFirst, skill scoping per task. Instead of exposing all 20+ skills to every agent, each terminal only sees the 3-5 skills relevant to its current dispatch. The orchestrator decides which skills to load before the agent even starts. Less noise, better selection accuracy.\nSecond, context rotation to prevent context rot setting in. When an agent's context fills up, the system automatically writes a structured handover, clears the window, and resumes in a fresh context. This is critical because a degraded context doesn't just pick worse tools — it starts ignoring instructions entirely. A fresh context with a good handover outperforms a bloated one every time.\nI'm actually testing automatic refresh at 60-70% usage right now — not waiting until the window is nearly full, but rotating early to prevent context rot before it starts. Early results suggest that's the sweet spot: late enough that you've done meaningful work, early enough that the handover quality is still high.\nThe organic discovery problem you're describing is essentially unsolvable with a flat tool list. The more tools you add, the worse selection gets — it's not linear degradation, it's closer to exponential once you pass ~15-20 tools in context. The only path I've found is hierarchical: a routing layer that narrows the set before the agent sees it.",
              "author": "vincentvandeth",
              "depth": 2
            }
          ]
        },
        {
          "top": "CRIPIX seems to be a new and unusual concept. I came across it recently and noticed it’s available on Amazon. The description mentions something called the Information Sovereign Anomaly and frames the work more like a technological and cognitive investigation than a traditional book. What caught my attention is that it appears to question current AI and computational assumptions rather than promote them. Has anyone here heard about it or looked into it ?",
          "author": "kellkell",
          "replies": [
            {
              "text": "The \"Sovereign Anomaly\" Concept (2025-2026): Recent literature, such as the 2025 book CRIPIX 1: The Information Sovereign Anomaly, explores scenarios where a \"superintelligent AI\" encounters code it cannot process, labelling it an \"out-of-model anomaly\" and suggesting that owning information sovereignty allows entities to \"bend reality\".",
              "author": "kellkell",
              "depth": 1
            },
            {
              "text": "bruh",
              "author": "dmpyatyi",
              "depth": 1
            }
          ]
        }
      ]
    },
    {
      "id": "47125345",
      "title": "GLP-1 Second-Order Effects",
      "link": "https://news.ycombinator.com/item?id=47125345",
      "domain": "news.ycombinator.com",
      "author": "7777777phil",
      "score": 22,
      "comment_count": 9,
      "created_ts": 1771867104,
      "is_internal": true,
      "post_text": "The first-order effects of GLP-1 drugs are obvious: people lose weight, Novo Nordisk and Eli Lilly print money. But what happens when 10-15% of the adult population is on weight-loss medication within a decade? The downstream consequences are less discussed and almost certainly not priced into anything.<p>In 2018, United Airlines switched to lighter paper for its inflight magazine. One ounce per copy. Across 4,500 daily flights, that saved 170,000 gallons of fuel a year [1]. Airlines think about weight at this level of granularity because fuel is their single largest variable cost.<p>Average weight loss on semaglutide is around 35 pounds per person. If 12% of passengers on a typical 737 have been on the drug, that&#x27;s roughly 750 fewer pounds per flight, the equivalent of shaving the weight off 12,000 magazines. United spent months optimizing paper stock to save $290,000 a year in fuel. GLP-1 adoption across the flying population could quietly save them an order of magnitude more, and ticket prices don&#x27;t adjust down when passengers get lighter.<p>The food supply chain is more obvious but larger in scale. If a big share of the population eats 20-30% less, demand for calories drops. Not a shift in preferences toward salads. A pharmacological reduction in how much people eat, period. The food industry has dealt with changing tastes before. It has never faced a demand shock from the medical system.<p>Health insurance has a subtler problem. The pitch for GLP-1 coverage is that the drugs prevent expensive conditions downstream: diabetes, heart disease, joint replacements. Probably true. But in America&#x27;s fragmented insurance market, the company paying for the drug today probably isn&#x27;t the one insuring that patient in five or ten years. The savings land on someone else&#x27;s balance sheet. That mismatch could slow adoption by years on its own.<p>Obesity correlates with lower workforce participation and higher absenteeism. If GLP-1s meaningfully reduce obesity rates, aggregate labor supply goes up. More people working, fewer health-related absences. That&#x27;s a macroeconomic stimulus, except nobody frames it that way because it comes from a pharmaceutical company rather than from Congress.<p>Early data suggests GLP-1s reduce cravings for alcohol, nicotine, and gambling too. Phase 2 trials for opioid use disorder are underway. A weight-loss drug that accidentally dents Diageo&#x27;s revenue and casino foot traffic was not in anybody&#x27;s original investment thesis for Ozempic.<p>The effect I find hardest to think about is the psychological one. Weight has been tangled up with shame, identity, and social hierarchy for centuries. What happens to body positivity, the social dynamics of attractiveness, the entire cultural machinery around diet and discipline when weight becomes something you manage with a prescription? I don&#x27;t have a good framework for it. Nothing comparable has happened before.<p>The market is treating this as a pharma story. The drug companies will capture a fraction of the total value created and destroyed. The rest redistributes across food, airlines, insurance, labor markets, and social behavior. Nobody&#x27;s model probably covers all of that at once.<p>[1] https:&#x2F;&#x2F;www.cbsnews.com&#x2F;news&#x2F;united-hemispheres-magazine-print-edition&#x2F;<p>EDIT: Formatting",
      "is_ask_hn": false,
      "matched_keywords": [
        "balance",
        "stock"
      ],
      "comments": [
        {
          "top": "This essay pulls together a few threads from pieces I've written over the past months on my blog, where I dig into rabbit holes like GLP-1 economics among other things.\nIf the pharma side interests you, I just wrote up Novo's rise and fall as Europe's most valuable company:\nhttps://philippdubach.com/posts/novo-was-europes-most-valuab...",
          "author": "7777777phil",
          "replies": [
            {
              "text": "Thanks for sharing. I quickly skimmed through the latest article on Novo and it looks quite interesting. Bookmarked for later exploration.",
              "author": "malshe",
              "depth": 1
            }
          ]
        },
        {
          "top": "GLP-1 drugs, as I understand it, reduce appetite. They don't magically add nutrients to the body. Of course the body will reduce cravings for alcohol, nicotine, and gambling. Nutrients would be prioritized over the poisons such as alcohol and nicotine. Additionally, why would the body prioritize what it considers fruitless dopamine release (gambling) when there are no nutrients coming in. The body literally can't afford to sit around and gamble since that resource isn't directly transferrable into food. It's literally in a starvation state.\nBut please, tell me how it's better than finally doing some exercise and eating right.",
          "author": "butlike",
          "replies": [
            {
              "text": "So you went from know it \"reduces appetite\" to make a bunch of conjectures about why it affects other things\n> But please, tell me how it's better than finally doing some exercise and eating right.\nBecause it actually works well?\nGood ol' fashioned gumption doesn't work, no matter how crankily and haughtily you say it. GLP-1s \ndo\nAlso, you don't mention why the things you listed are \nbad\n. Any weight loss will require a calorie deficit, which has the same \"starvation\" you're so aghast at.",
              "author": "xorbax",
              "depth": 1
            },
            {
              "text": "Lack of resource adds stress to the body, plain and simple. Exercising without a caloric deficit can build muscle. Weight loss without exercise is all loss no gain while maintaining a stressful state on the body.\nAnd \"good ol' fashioned gumption\" does work, at least for me. (Sample size: 1)",
              "author": "butlike",
              "depth": 2
            },
            {
              "text": "Define “stress”.\nCalorie restriction is demonstrably life-extending in multiple species (that it’s feasible to test it in).",
              "author": "mft_",
              "depth": 3
            },
            {
              "text": "How did you get from reduced appetite to starvation state? I'm not on one of these drugs myself, but from friends I've been talking to, it seems like (after a bit of dosage tuning) it's reducing their appetite to what would be expected from a person who never was obese. So they do lose weight relatively rapidly, especially at the start, but I don't see why we should equate weight loss with starvation.\nAs for \"how it's better\", - the answer is clearly that unlike \"exercise and eating right\", these drugs are leading to positive behavioral change at scale. I'm perhaps slightly exaggerating, but to the best of my knowledge, no other substance over the last several thousand years has had such a clear positive effect on humanity as a whole.",
              "author": "falcor84",
              "depth": 1
            },
            {
              "text": "Still don't understand why we need positive behavioral changes \"at scale,\" but I'm going to leave it at: if it works, I'm happy for you.",
              "author": "butlike",
              "depth": 2
            }
          ]
        }
      ]
    },
    {
      "id": "47105086",
      "title": "Ask HN: Programmable Watches with WiFi?",
      "link": "https://news.ycombinator.com/item?id=47105086",
      "domain": "news.ycombinator.com",
      "author": "dakiol",
      "score": 21,
      "comment_count": 10,
      "created_ts": 1771709995,
      "is_internal": true,
      "post_text": "Hi. I&#x27;m looking for a programmable watch with wifi. Ideally I should be able to write custom programs&#x2F;apps for the watch to display whatever I want to on them (e.g., make the watch make an https call to a server, receive json and render accordingly; allow the watch to receive &quot;notifications&quot; from the server)<p>Also, ideally, no requirement of a smartphone to send-receive data (it&#x27;s ok to need a smartphone for the initial setup of the watch, though). I know about Pebble, but it doesn&#x27;t have wifi. I know about some Garmins with wifi but for the kind of apps I want to write, the communication between the watch and the server has to be mediated by a phone. Also, correct me if I&#x27;m wrong, I don&#x27;t want to pay $100&#x2F;year just to be able to use my custom app in apple watches. I usually don&#x27;t trust Google either (e.g., they discontinue everything in a blink of an eye).<p>So, what are my options?",
      "is_ask_hn": true,
      "matched_keywords": [
        "communication"
      ],
      "comments": [
        {
          "top": "Bangle is a good one \nhttps://banglejs.com/\n\nQuite fun to work with. I got one from a conference, and my kid has been enjoying it a lot.",
          "author": "huydotnet",
          "replies": [
            {
              "text": "Wonder if you could get Clojure (through the SCI) running on it.\nHow is the general watch API? The development experience?\nis there some community or list of exciting projects made for it? for inspiration :)",
              "author": "geokon",
              "depth": 1
            },
            {
              "text": "When your watch supports the most common computer language on Earth, it is hard to go wrong with it. 4 week standby is pretty good too.",
              "author": "mycall",
              "depth": 1
            }
          ]
        },
        {
          "top": "I have one of the TTGO T-watches: \nhttps://www.tinytronics.nl/en/development-boards/microcontro...\nFor me it is mainly a decoration of my drawer, but maybe comes close to what you are looking for. :)",
          "author": "oliwary",
          "replies": []
        },
        {
          "top": "Wear OS watches commonly have wifi, and can be programmed with the standard Android API and toolchain/IDEs. I doubt that Google will discontinue Wear OS - although your evaluation of risk will undoubtedly depend on whether you're looking at developing personal or commercial apps.\nI'm currently wearing a TicWatch Pro 3 Ultra, which has wifi, Bluetooth, and GPS. I've written personal tools for it, and its fairly painless (and free). As a developer with some background in Android, I enjoyed the experience. Getting apps approved for the app store is a pita though, as Google sets quite high bars for the review process.\nI also have a Samsung Galaxy Watch4, which also has wifi. People here speak well of Pebble, which might be an option, but I have no real knowledge of it.\nFinally, though, wifi is power-hungry and watches have limited batteries and endurance. Both Wear OS and WatchOS will limit wifi use by apps to conserve power, and you ultimately can't do much about that. Using Bluetooth to a phone, and its much greater wifi capacity, is a common approach.",
          "author": "andyjohnson0",
          "replies": []
        },
        {
          "top": "AsteroidOS, which runs on many Android watches, and offers a Linux environment over SSH and WiFi (for watches that support it). \nhttps://asteroidos.org/\nThe simplest integration is writing a daemon (in the language of your choice) that schedules wakes, syncs, and sends FreeDesktop notifications.\nIf you want more of a UI, then you'll be writing QtQuick, which is QML/Javascript/C++.\nTheir best supported watch is the TicWatch Pro: \nhttps://asteroidos.org/watches/catfish/",
          "author": "griffindor",
          "replies": []
        },
        {
          "top": "You should definitely check out the pinetime. I’m about to pick one up myself. For ~30 bucks why not.\nDefault OS is a community project. I followed development for a few years. It’s pretty solid last I checked with good battery life and support for user apps written in rust",
          "author": "curioussavage",
          "replies": []
        }
      ]
    },
    {
      "id": "47132766",
      "title": "Would you choose the Microsoft stack today if starting greenfield?",
      "link": "https://news.ycombinator.com/item?id=47132766",
      "domain": "news.ycombinator.com",
      "author": "JB_5000",
      "score": 17,
      "comment_count": 16,
      "created_ts": 1771906275,
      "is_internal": true,
      "post_text": "Serious question.<p>Outside government or heavily regulated enterprise, what is Microsoft’s core value prop in 2026?<p>It feels like a lot of adoption is inherited — contracts, compliance, enterprise trust, existing org gravity. Not necessarily technical preference.<p>If you were starting from scratch today with no legacy, no E5 contracts, no sunk cost — how many teams would actually choose the full MS stack over best-of-breed tools?<p>Curious what people here have actually chosen in greenfield builds.",
      "is_ask_hn": false,
      "matched_keywords": [
        "enterprise"
      ],
      "comments": [
        {
          "top": "I know it's not popular, but I think Powershell returning objects is quite nice. It seems much better/easier than trying to parse raw text in Linux.\nThat said, if I'm making something new, I never go with an MS stack. I just wish I had some Powershell type options in Linux from time to time.",
          "author": "al_borland",
          "replies": [
            {
              "text": "PowerShell is available for Linux and MacOS.  Which means you can have the tool you like and run on a non-MS platform.",
              "author": "burntoutgray",
              "depth": 1
            },
            {
              "text": "I know it's available, but I always assumed it would be a 2nd class citizen.\nI just tried to install in on my personal macOS system. I tried brew, as Microsoft gives instructions for it...\n> Warning: powershell has been deprecated because it does not pass the macOS Gatekeeper check! It will be disabled on 2026-09-01.\nIt went on to do more and then prompted for my password, but I canceled out of it. I'm not looking to get started with anything that starts with a deprecation warning. This is what I'm talking about when I say it feels like a 2nd class citizen. I can only assume I can't use 100% Powershell to admin a system, like one could with Windows.",
              "author": "al_borland",
              "depth": 2
            }
          ]
        },
        {
          "top": "I am building a new product from scratch in .NET. Not the full traditional MS stack but just .NET for backend and VueJS for frontend and Postgres for DB. I don't use things like Azure, SQL Server etc but .NET is solid. So yes.",
          "author": "codegeek",
          "replies": []
        },
        {
          "top": "Hell no?\nHow is this even a question?",
          "author": "tim-tday",
          "replies": []
        },
        {
          "top": "What are the \"best of breed\" tools in your opinion?\nIn the enterprise world, dotnet with c# is one of the best choices, although recently I've been doing a lot of logic just with python running on serverless functions.",
          "author": "thorin",
          "replies": []
        },
        {
          "top": "I never chose MS, ever. Most systems have been based on Debian servers. Some special needs I've used Alpine Linux and NetBSD (yes it does run on older, limited hardware).\nOf course, some potential clients demand MS based solutions. I simply decline those contracts and ring them up 12-18 months later to see if the CTO/CIO has been replaced.",
          "author": "burntoutgray",
          "replies": []
        }
      ]
    },
    {
      "id": "47128495",
      "title": "Ask HN: Where do you save links, notes and random useful stuff?",
      "link": "https://news.ycombinator.com/item?id=47128495",
      "domain": "news.ycombinator.com",
      "author": "a_protsyuk",
      "score": 17,
      "comment_count": 38,
      "created_ts": 1771879303,
      "is_internal": true,
      "post_text": "I have 2,600+ notes in Apple Notes and can barely find anything.<p>My kid just dumps everything into Telegram saved messages. Running a small research - curious what systems people actually use (not aspire to use).<p>Do you have a setup that works or is everything scattered across 5 apps like mine?",
      "is_ask_hn": true,
      "matched_keywords": [],
      "comments": [
        {
          "top": "My only friction with hierarchy-type store of bookmarks is the orthogonal labeling scheme remains poorly or unsupported.\nSlapping a tag or two (or many) is bandaid.\nNeed a way to navigate a tree for a bookmark that is repeatedly tagged and filed across hierarchy.\nPerfect example: retirement, budget, investment firms, reviewed\nEach day has a focus, and it often arrives differently to a same bookmark.\nHandcrafted Wikipedia category tree is a good start but still no navigation panel and a search box thereof.",
          "author": "egberts1",
          "replies": [
            {
              "text": "This is the fundamental problem with hierarchies - knowledge is multi-dimensional but folders are one-dimensional. You shouldn't have to decide if \"Vanguard 2026 review\" lives under /retirement or /budget or /investments. What if you could just search \"retirement investment options I reviewed\" and find it regardless of where it was filed - by meaning, not by path?",
              "author": "a_protsyuk",
              "depth": 1
            }
          ]
        },
        {
          "top": "The real issue isn't where you store notes — it's whether you find them when you actually need them.\nI've gone through Notion, Confluence, and plain markdown. The pattern is always the same: I diligently save everything, then never look at it again because the moment I need it, I'm in a completely different context (a ticket, a chat, a meeting).\nThe \"low friction = actually use it\" point resonates. I've started thinking the answer isn't a better note-taking app, but surfacing the right information where the work happens, rather than making people go find it.",
          "author": "moowmoow",
          "replies": [
            {
              "text": "This is actually the truth, we all have tens or hundreds of priceless saved links. However, I claim that 90% are forgotten after a day or two, maybe that's actually something that small language models can fix ?",
              "author": "bawis",
              "depth": 1
            }
          ]
        },
        {
          "top": "My system is basically a 'digital graveyard' if I don't use full-text search. I moved everything to Obsidian because it's just Markdown files on my drive. For links, I use a simple Telegram bot I wrote that dumps everything into a CSV. Low tech, but it’s the only thing I’ve actually stuck with for more than a year.",
          "author": "CodeBit26",
          "replies": []
        },
        {
          "top": "using obsidian for notes raindrop.io for bookmarks and have my own jekyll template just for public links\nhttps://github.com/umtksa/links\n (repo)\nhttps://umtksa.github.io/links/\n (demo)",
          "author": "umtksa",
          "replies": []
        },
        {
          "top": "Tools: Zettlr for notes. user?weird_tentacles explained the concept of zellelkasten.  These are synced to a cloud folder so I have access to them on the move.\nBlog: Compiling notes into 'new' knowledge is challenging and interesting. I try to keep on doing what I did in postgrad research.",
          "author": "throwaway5465",
          "replies": [
            {
              "text": "Zettlr is underrated. When you're compiling notes into something new - how do you find the right notes to pull together? Do you browse, search, or does the linking do the work?",
              "author": "a_protsyuk",
              "depth": 1
            },
            {
              "text": "Memory, notes hierarchy and filename (I tend to keep notes conceptually atomic and not just the date/time as a filename), tag search, free text search, citation backsearch; I have a bibtex library linked but that's mainly focused on maintaining references to published work- I use JabRef but IMHO that's really too heavy for what I use it for.",
              "author": "throwaway5465",
              "depth": 2
            }
          ]
        }
      ]
    },
    {
      "id": "47106013",
      "title": "Ask HN: If the \"AI bubble\" pops, will it really be that dramatic?",
      "link": "https://news.ycombinator.com/item?id=47106013",
      "domain": "news.ycombinator.com",
      "author": "moomoo11",
      "score": 14,
      "comment_count": 11,
      "created_ts": 1771715714,
      "is_internal": true,
      "post_text": "I&#x27;m building software for a sector that is massive, but one where you don&#x27;t really need AI. At least, not AI == LLM.<p>And before I go further, let me state up front that I do like AI coding agents. They are great as assistive tools.<p>People say that if the AI bubble pops, the economy tumbles. And okay, I mean the M7 will certainly get rekt but everyone else? Things will recover within a few years. We didn&#x27;t make it to 2026 AD taking the easy road.<p>You still need to visit the doctor. Goods still need to be delivered. Homes need to be built. We need to drill for oil. People still need to eat. And yes, unfortunately or not, we still need millions of administrators because humans are not 0&#x2F;1 systems.<p>Am I crazy to think that maybe it won&#x27;t be that bad? There are still infinite number of things to do, and maybe (call me stupid, whatever) it would be a good turning point for our species if we realize that speculative bubbles are absolutely destructive and not worth it.<p>I don&#x27;t need a personal assistant to make calls for me to get a restaurant reservation, and I certainly don&#x27;t care for AI slop videos. I would much rather we have better products and services that actually work, and even if they have rough edges I would prefer people are employed and busy doing something with their lives.<p>Maybe a world where we don&#x27;t chase endless growth (to escape inflation, pay off debts, whatever the case) would be good. And also we put nerds (not people like us, the engineers, I mean the evil dorks who cosplay as movie super villains) in the toy box again and pick up different toys this time.",
      "is_ask_hn": true,
      "matched_keywords": [],
      "comments": [
        {
          "top": "Well, the Great Fiscal Crisis did not result in mass starvation, so in some sense, it \"wasn't all that dramatic\".  But, it was a big deal in comparison to a normal downturn.  So, it depends on what you mean.\nMedium term, I think it would release a lot of resources (skilled workers, productive capacity, energy) to use on something more productive.  But then, I kind of hoped for that after the GFC, also...",
          "author": "rossdavidh",
          "replies": []
        },
        {
          "top": "No the economy doesn’t tumble. All of the major public tech companies have real businesses that were profitable before AI and will be profitable after AI.  All except Amazon are spending money out of their own revenues.\nBusinesses aren’t going to stop growing because of AI, the only public company really dependent on AI are NVidia and Oracle. Oracle because it is borrowing money to support build out for OpenAI.",
          "author": "raw_anon_1111",
          "replies": [
            {
              "text": "lol @ “all except amazon are spending their own revenues…”\nhttps://www.cnbc.com/amp/2026/02/12/alphabet-100-year-bond-d...",
              "author": "bdangubic",
              "depth": 1
            },
            {
              "text": "Apple also borrowed money - pre AI when it had plenty of cash,  have you checked Google’s last year earnings and cash on hand?",
              "author": "raw_anon_1111",
              "depth": 2
            },
            {
              "text": "> all except Amazon are spending money out of their own revenues.\nso apple and google and amazon and…? :)\nearnings and cash on hand are not relevant, they are all borrowing like crazy to fund the ai",
              "author": "bdangubic",
              "depth": 3
            },
            {
              "text": "Apple was borrowing like crazy before AI.  How much money do you think Apple is spending on AI aside from the $1 billion they are paying for Gemini?  That’s less than 1% of their profit and hell that’s less than 5% of what Google pays them.",
              "author": "raw_anon_1111",
              "depth": 4
            },
            {
              "text": "I didn’t think we debating whether or not they are spending but whether they are borrowing (you said only amazon is) - and they are borrowing, not just amazon",
              "author": "bdangubic",
              "depth": 5
            }
          ]
        },
        {
          "top": "Related: \nhttps://news.ycombinator.com/item?id=47034849",
          "author": "lyfeninja",
          "replies": []
        },
        {
          "top": "The AI bubble won't really \"pop because it isn't a bubble in the traditional sense.\nAI isn't being speculated on nearly as bad as crypto was in 2021, or housing was in 2007, or dotcom era businesses were in 2000.\nRevenues are ballooning like crazy for AI providers. There is insane demand for AI compute, meaning valuations are justified by revenue, not chasing hyper-speculation.\nWhat may happen is that regulatory environments make the next generation of models unviable for release (because they are too dangerous to release and no AI company wants to deal with the liability), which would lead to lower API revenues and thus a sell-off. However any API that's too dangerous to release would be extremely powerful as something the AI companies use on their own to push products/research forward, which would still increase their revenue.",
          "author": "atleastoptimal",
          "replies": []
        },
        {
          "top": "A pop hurts valuations, not demand for useful software.",
          "author": "lyaocean",
          "replies": []
        }
      ]
    },
    {
      "id": "47113891",
      "title": "Ask HN: Cognitive Offloading to AI",
      "link": "https://news.ycombinator.com/item?id=47113891",
      "domain": "news.ycombinator.com",
      "author": "daringrain32781",
      "score": 12,
      "comment_count": 8,
      "created_ts": 1771788792,
      "is_internal": true,
      "post_text": "I ask questions to co workers about a system or why they do something or their opinion. Some of them return a very clearly AI response, sometimes completely missing the point. What’s the point? If I wanted an AI response I’d have asked it myself.<p>This bothers me a bit because if I can expect this kind of response, what does that say about the thought they put into their work, even if they’re using AI for everything coding related?",
      "is_ask_hn": true,
      "matched_keywords": [],
      "comments": [
        {
          "top": "I think the question is why didn't you ask the AI and then if you need more information ask the human including what you learned from AI.",
          "author": "jf22",
          "replies": [
            {
              "text": "If I thought AI would have given me the answer I needed then I would have used it.",
              "author": "daringrain32781",
              "depth": 1
            }
          ]
        },
        {
          "top": "That reminds me of one joke that I heard recently:\n- Dad, dad, do you and your colleagues use artificial intelligence at work?\n- Oh, dear, we don't even use natural intelligence...\nAs they say, every joke has a grain of truth in it. There are people who, in principle, do not think about why they do something or what the consequences will be. That's just the way they are.",
          "author": "dryarzeg",
          "replies": []
        },
        {
          "top": "Sometimes it seems that the primary \"benefit\" / use case for AI is that people can use it, and if it outputs something useful then they look like they are AI early adopters, geniuses, etc, and if it outputs something dumb, then it's not their fault, it's the AI.\nEither way, they get the upside, and apparently now it's your job to sort the AI slop from the reality, for some reason.\nA few times, I have pointed out to people that their AI slop is wrong, and they said \"yeah, it's wrong sometimes, but humans are also wrong sometimes, so it's no better/worse\". It's the same logic as self-driving cars that kill people being fine, because after human-driven cars also kill people. It's true, but that's a _problem_....",
          "author": "tacostakohashi",
          "replies": []
        },
        {
          "top": "Quite honestly that sucks. To quote someone elsewhere on the internet, \"offloading the most human interaction to an AI implies that you're only as human as the AI.\"",
          "author": "yvyn",
          "replies": []
        },
        {
          "top": "> Some of them return a very clearly AI response, sometimes completely missing the point. What’s the point?\nThe point is as always: to get the work \"done\" faster.\n> If I wanted an AI response I’d have asked it myself.\nSuch people are generally not bright enough to see the difference, so certainly not bright enough to realise you can.",
          "author": "chrisjj",
          "replies": [
            {
              "text": "Good try, tovarish major. Good try.",
              "author": "dryarzeg",
              "depth": 1
            }
          ]
        }
      ]
    }
  ]
}