{
  "scraped_date": "2026-02-22",
  "source": "newsletters",
  "feeds_checked": [
    "simon_willison",
    "marcus_on_ai",
    "pragmatic_engineer",
    "lenny",
    "software_lead_weekly",
    "leaddev",
    "staffeng",
    "engineering_managers"
  ],
  "total_articles": 45,
  "relevant_count": 33,
  "articles": [
    {
      "feed_id": "lenny",
      "feed_name": "Lenny's Newsletter",
      "title": "Sequoia CEO coach: Why it‚Äôs never been easier to start a company, and never been harder to scale one | Brian Halligan (co-founder, HubSpot)",
      "summary": "Listen now | From HubSpot to Sequoia: Brian Halligan on scaling, leadership, AI, hiring mistakes, and the crisis that changed his life",
      "link": "https://www.lennysnewsletter.com/p/sequoia-ceo-coach-why-its-never-been",
      "published": "2026-02-15T13:31:20+00:00",
      "matched_keywords": [
        "leadership",
        "ai",
        "hiring"
      ],
      "relevance_score": 5,
      "feed_focus": [
        "product",
        "growth",
        "leadership"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "ggml.ai joins Hugging Face to ensure the long-term progress of Local AI",
      "summary": "ggml.ai joins Hugging Face to ensure the long-term progress of Local AI I don't normally cover acquisition news like this, but I have some thoughts. It's hard to overstate the impact Georgi Gerganov has had on the local model space. Back in March 2023 his release of llama.cpp made it possible to run a local LLM on consumer hardware. The original README said: The main goal is to run the model using 4-bit quantization on a MacBook. [...] This was hacked in an evening - I have no idea if it works c",
      "link": "https://simonwillison.net/2026/Feb/20/ggmlai-joins-hugging-face/#atom-everything",
      "published": "2026-02-20T17:12:55+00:00",
      "matched_keywords": [
        "team",
        "ai",
        "impact",
        "influence"
      ],
      "relevance_score": 4,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Gemini 3.1 Pro",
      "summary": "Gemini 3.1 Pro The first in the Gemini 3.1 series, priced the same as Gemini 3 Pro ($2/million input, $12/million output under 200,000 tokens, $4/$18 for 200,000 to 1,000,000). That's less than half the price of Claude Opus 4.6 with very similar benchmark scores to that model. They boast about its improved SVG animation performance compared to Gemini 3 Pro in the announcement! I tried \"Generate an SVG of a pelican riding a bicycle\" in Google AI Studio and it thought for 323.9 seconds (thinking t",
      "link": "https://simonwillison.net/2026/Feb/19/gemini-31-pro/#atom-everything",
      "published": "2026-02-19T17:58:37+00:00",
      "matched_keywords": [
        "team",
        "ai",
        "performance"
      ],
      "relevance_score": 3,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "The A.I. Disruption We‚Äôve Been Waiting for Has Arrived",
      "summary": "The A.I. Disruption We‚Äôve Been Waiting for Has Arrived New opinion piece from Paul Ford in the New York Times. Unsurprisingly for a piece by Paul it's packed with quoteworthy snippets, but a few stood out for me in particular. Paul describes the November moment that so many other programmers have observed, and highlights Claude Code's ability to revive old side projects: [Claude Code] was always a helpful coding assistant, but in November it suddenly got much better, and ever since I‚Äôve been kno",
      "link": "https://simonwillison.net/2026/Feb/18/the-ai-disruption/#atom-everything",
      "published": "2026-02-18T17:07:31+00:00",
      "matched_keywords": [
        "ai",
        "impact",
        "senior"
      ],
      "relevance_score": 3,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Two new Showboat tools: Chartroom and datasette-showboat",
      "summary": "I introduced Showboat a week ago - my CLI tool that helps coding agents create Markdown documents that demonstrate the code that they have created. I've been finding new ways to use it on a daily basis, and I've just released two new tools to help get the best out of the Showboat pattern. Chartroom is a CLI charting tool that works well with Showboat, and datasette-showboat lets Showboat's new remote publishing feature incrementally push documents to a Datasette instance. Showboat remote publish",
      "link": "https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#atom-everything",
      "published": "2026-02-17T00:43:45+00:00",
      "matched_keywords": [
        "feedback",
        "ai",
        "remote"
      ],
      "relevance_score": 3,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "The AI Vampire",
      "summary": "The AI Vampire Steve Yegge's take on agent fatigue, and its relationship to burnout. Let's pretend you're the only person at your company using AI. In Scenario A, you decide you're going to impress your employer, and work for 8 hours a day at 10x productivity. You knock it out of the park and make everyone else look terrible by comparison. In that scenario, your employer captures 100% of the value from you adopting AI. You get nothing, or at any rate, it ain't gonna be 9x your salary. And everyo",
      "link": "https://simonwillison.net/2026/Feb/15/the-ai-vampire/#atom-everything",
      "published": "2026-02-15T23:59:36+00:00",
      "matched_keywords": [
        "ai",
        "burnout",
        "career"
      ],
      "relevance_score": 3,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Quoting Thibault Sottiaux",
      "summary": "We‚Äôve made GPT-5.3-Codex-Spark about 30% faster. It is now serving at over 1200 tokens per second. &mdash; Thibault Sottiaux, OpenAI Tags: openai, llms, ai, generative-ai, llm-performance",
      "link": "https://simonwillison.net/2026/Feb/21/thibault-sottiaux/#atom-everything",
      "published": "2026-02-21T01:30:21+00:00",
      "matched_keywords": [
        "ai",
        "performance"
      ],
      "relevance_score": 2,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Taalas serves Llama 3.1 8B at 17,000 tokens/second",
      "summary": "Taalas serves Llama 3.1 8B at 17,000 tokens/second This new Canadian hardware startup just announced their first product - a custom hardware implementation of the Llama 3.1 8B model (from July 2024) that can run at a staggering 17,000 tokens/second. I was going to include a video of their demo but it's so fast it would look more like a screenshot. You can try it out at chatjimmy.ai. They describe their Silicon Llama as ‚Äúaggressively quantized, combining 3-bit and 6-bit parameters.‚Äù Their next ge",
      "link": "https://simonwillison.net/2026/Feb/20/taalas/#atom-everything",
      "published": "2026-02-20T22:10:04+00:00",
      "matched_keywords": [
        "ai",
        "performance"
      ],
      "relevance_score": 2,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "SWE-bench February 2026 leaderboard update",
      "summary": "SWE-bench February 2026 leaderboard update SWE-bench is one of the benchmarks that the labs love to list in their model releases. The official leaderboard is infrequently updated but they just did a full run of it against the current generation of models, which is notable because it's always good to see benchmark results like this that weren't self-reported by the labs. The fresh results are for their \"Bash Only\" benchmark, which runs their mini-swe-bench agent (~9,000 lines of Python, here are ",
      "link": "https://simonwillison.net/2026/Feb/19/swe-bench/#atom-everything",
      "published": "2026-02-19T04:48:47+00:00",
      "matched_keywords": [
        "ai",
        "strategy"
      ],
      "relevance_score": 2,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Typing without having to type",
      "summary": "25+ years into my career as a programmer I think I may finally be coming around to preferring type hints or even strong typing. I resisted those in the past because they slowed down the rate at which I could iterate on code, especially in the REPL environments that were key to my productivity. But if a coding agent is doing all that typing for me, the benefits of explicitly defining all of those types are suddenly much more attractive. Tags: ai-assisted-programming, programming, programming-lang",
      "link": "https://simonwillison.net/2026/Feb/18/typing/#atom-everything",
      "published": "2026-02-18T18:56:56+00:00",
      "matched_keywords": [
        "ai",
        "career"
      ],
      "relevance_score": 2,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Introducing Claude Sonnet 4.6",
      "summary": "Introducing Claude Sonnet 4.6 Sonnet 4.6 is out today, and Anthropic claim it offers similar performance to November's Opus 4.5 while maintaining the Sonnet pricing of $3/million input and $15/million output tokens (the Opus models are $5/$25). Here's the system card PDF. Sonnet 4.6 has a \"reliable knowledge cutoff\" of August 2025, compared to Opus 4.6's May 2025 and Haiku 4.5's February 2025. Both Opus and Sonnet default to 200,000 max input tokens but can stretch to 1 million in beta and at a ",
      "link": "https://simonwillison.net/2026/Feb/17/claude-sonnet-46/#atom-everything",
      "published": "2026-02-17T23:58:58+00:00",
      "matched_keywords": [
        "ai",
        "performance"
      ],
      "relevance_score": 2,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Nano Banana Pro diff to webcomic",
      "summary": "Given the threat of cognitive debt brought on by AI-accelerated software development leading to more projects and less deep understanding of how they work and what they actually do, it's interesting to consider artifacts that might be able to help. Nathan Baschez on Twitter: my current favorite trick for reducing \"cognitive debt\" (h/t @simonw ) is to ask the LLM to write two versions of the plan: The version for it (highly technical and detailed) The version for me (an entertaining essay designe",
      "link": "https://simonwillison.net/2026/Feb/17/release-notes-webcomic/#atom-everything",
      "published": "2026-02-17T04:51:58+00:00",
      "matched_keywords": [
        "ai",
        "remote"
      ],
      "relevance_score": 2,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Deep Blue",
      "summary": "We coined a new term on the Oxide and Friends podcast last month (primary credit to Adam Leventhal) covering the sense of psychological ennui leading into existential dread that many software developers are feeling thanks to the encroachment of generative AI into their field of work. We're calling it Deep Blue. You can listen to it being coined in real time from 47:15 in the episode. I've included a transcript below. Deep Blue is a very real issue. Becoming a professional software engineer is ha",
      "link": "https://simonwillison.net/2026/Feb/15/deep-blue/#atom-everything",
      "published": "2026-02-15T21:06:44+00:00",
      "matched_keywords": [
        "ai",
        "career"
      ],
      "relevance_score": 2,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "How Generative and Agentic AI Shift Concern from Technical Debt to Cognitive Debt",
      "summary": "How Generative and Agentic AI Shift Concern from Technical Debt to Cognitive Debt This piece by Margaret-Anne Storey is the best explanation of the term cognitive debt I've seen so far. Cognitive debt, a term gaining traction recently, instead communicates the notion that the debt compounded from going fast lives in the brains of the developers and affects their lived experiences and abilities to ‚Äúgo fast‚Äù or to make changes. Even if AI agents produce code that could be easy to understand, the h",
      "link": "https://simonwillison.net/2026/Feb/15/cognitive-debt/#atom-everything",
      "published": "2026-02-15T05:20:11+00:00",
      "matched_keywords": [
        "team",
        "ai"
      ],
      "relevance_score": 2,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Andrej Karpathy talks about \"Claws\"",
      "summary": "Andrej Karpathy talks about &quot;Claws&quot; Andrej Karpathy tweeted a mini-essay about buying a Mac Mini (\"The apple store person told me they are selling like hotcakes and everyone is confused\") to tinker with Claws: I'm definitely a bit sus'd to run OpenClaw specifically [...] But I do love the concept and I think that just like LLM agents were a new layer on top of LLMs, Claws are now a new layer on top of LLM agents, taking the orchestration, scheduling, context, tool calls and a kind of p",
      "link": "https://simonwillison.net/2026/Feb/21/claws/#atom-everything",
      "published": "2026-02-21T00:37:45+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Adding TILs, releases, museums, tools and research to my blog",
      "summary": "I've been wanting to add indications of my various other online activities to my blog for a while now. I just turned on a new feature I'm calling \"beats\" (after story beats, naming this was hard!) which adds five new types of content to my site, all corresponding to activity elsewhere. Here's what beats look like: Those three are from the 30th December 2025 archive page. Beats are little inline links with badges that fit into different content timeline views around my site, including the homepag",
      "link": "https://simonwillison.net/2026/Feb/20/beats/#atom-everything",
      "published": "2026-02-20T23:47:10+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Quoting Thariq Shihipar",
      "summary": "Long running agentic products like Claude Code are made feasible by prompt caching which allows us to reuse computation from previous roundtrips and significantly decrease latency and cost. [...] At Claude Code, we build our entire harness around prompt caching. A high prompt cache hit rate decreases costs and helps us create more generous rate limits for our subscription plans, so we run alerts on our prompt cache hit rate and declare SEVs if they're too low. &mdash; Thariq Shihipar Tags: promp",
      "link": "https://simonwillison.net/2026/Feb/20/thariq-shihipar/#atom-everything",
      "published": "2026-02-20T07:13:19+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Recovering lost code",
      "summary": "Reached the stage of parallel agent psychosis where I've lost a whole feature - I know I had it yesterday, but I can't seem to find the branch or worktree or cloud instance or checkout with it in. ... found it! Turns out I'd been hacking on a random prototype in /tmp and then my computer crashed and rebooted and I lost the code... but it's all still there in ~/.claude/projects/ session logs and Claude Code can extract it out and spin up the missing feature again. Tags: parallel-agents, coding-ag",
      "link": "https://simonwillison.net/2026/Feb/19/recovering-lost-code/#atom-everything",
      "published": "2026-02-19T23:48:35+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Quoting Martin Fowler",
      "summary": "LLMs are eating specialty skills. There will be less use of specialist front-end and back-end developers as the LLM-driving skills become more important than the details of platform usage. Will this lead to a greater recognition of the role of Expert Generalists? Or will the ability of LLMs to write lots of code mean they code around the silos rather than eliminating them? &mdash; Martin Fowler, tidbits from the Thoughtworks Future of Software Development Retreat, via HN) Tags: martin-fowler, ca",
      "link": "https://simonwillison.net/2026/Feb/18/martin-fowler/#atom-everything",
      "published": "2026-02-18T16:50:07+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Quoting Dimitris Papailiopoulos",
      "summary": "But the intellectually interesting part for me is something else. I now have something close to a magic box where I throw in a question and a first answer comes back basically for free, in terms of human effort. Before this, the way I'd explore a new idea is to either clumsily put something together myself or ask a student to run something short for signal, and if it's there, we‚Äôd go deeper. That quick signal step, i.e., finding out if a question has any meat to it, is what I can now do without ",
      "link": "https://simonwillison.net/2026/Feb/17/dimitris-papailiopoulos/#atom-everything",
      "published": "2026-02-17T14:04:44+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Qwen3.5: Towards Native Multimodal Agents",
      "summary": "Qwen3.5: Towards Native Multimodal Agents Alibaba's Qwen just released the first two models in the Qwen 3.5 series - one open weights, one proprietary. Both are multi-modal for vision input. The open weight one is a Mixture of Experts model called Qwen3.5-397B-A17B. Interesting to see Qwen call out serving efficiency as a benefit of that architecture: Built on an innovative hybrid architecture that fuses linear attention (via Gated Delta Networks) with a sparse mixture-of-experts, the model atta",
      "link": "https://simonwillison.net/2026/Feb/17/qwen35/#atom-everything",
      "published": "2026-02-17T04:30:57+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Rodney and Claude Code for Desktop",
      "summary": "I'm a very heavy user of Claude Code on the web, Anthropic's excellent but poorly named cloud version of Claude Code where everything runs in a container environment managed by them, greatly reducing the risk of anything bad happening to a computer I care about. I don't use the web interface at all (hence my dislike of the name) - I access it exclusively through their native iPhone and Mac desktop apps. Something I particularly appreciate about the desktop app is that it lets you see images that",
      "link": "https://simonwillison.net/2026/Feb/16/rodney-claude-code/#atom-everything",
      "published": "2026-02-16T16:38:57+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Em dash",
      "summary": "I'm occasionally accused of using LLMs to write the content on my blog. I don't do that, and I don't think my writing has much of an LLM smell to it... with one notable exception: # Finally, do em dashes s = s.replace(' - ', u'\\u2014') That code to add em dashes to my posts dates back to at least 2015 when I ported my blog from an older version of Django (in a long-lost Mercurial repository) and started afresh on GitHub. Tags: generative-ai, typography, blogging, ai, llms, python",
      "link": "https://simonwillison.net/2026/Feb/15/em-dashes/#atom-everything",
      "published": "2026-02-15T21:40:46+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "simon_willison",
      "feed_name": "Simon Willison's Weblog",
      "title": "Three months of OpenClaw",
      "summary": "It's wild that the first commit to OpenClaw was on November 25th 2025, and less than three months later it's hit 10,000 commits from 600 contributors, attracted 196,000 GitHub stars and sort-of been featured in an extremely vague Super Bowl commercial for AI.com. Quoting AI.com founder Kris Marszalek, purchaser of the most expensive domain in history for $70m: ai.com is the world‚Äôs first easy-to-use and secure implementation of OpenClaw, the open source agent framework that went viral two weeks ",
      "link": "https://simonwillison.net/2026/Feb/15/openclaw/#atom-everything",
      "published": "2026-02-15T17:23:28+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "ai",
        "engineering",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "pragmatic_engineer",
      "feed_name": "The Pragmatic Engineer",
      "title": "The Pulse #162: Even fewer middle managers and more flexible teams?",
      "summary": "Also: Anthropic bans third-party devs while Codex embraces them, Peter Steinberger joins OpenAI, a lot more software gets created with AI, and more",
      "link": "https://newsletter.pragmaticengineer.com/p/the-pulse-162-even-fewer-middle-managers",
      "published": "2026-02-19T19:09:08+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "engineering",
        "management",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "pragmatic_engineer",
      "feed_name": "The Pragmatic Engineer",
      "title": "How Codex is built",
      "summary": "A deepdive into how OpenAI's Codex team builds its coding agent, how engineers use it, and what it could mean for the future of software engineering. Exclusive",
      "link": "https://newsletter.pragmaticengineer.com/p/how-codex-is-built",
      "published": "2026-02-17T17:42:14+00:00",
      "matched_keywords": [
        "team"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "engineering",
        "management",
        "career",
        "big tech"
      ]
    },
    {
      "feed_id": "lenny",
      "feed_name": "Lenny's Newsletter",
      "title": "Head of Claude Code: What happens after coding is solved | Boris Cherny",
      "summary": "Listen now | Anthropic&#8217;s Boris Cherny on building Claude Code, how to maximize AI productivity, and what comes next after coding is &#8220;solved&#8221;",
      "link": "https://www.lennysnewsletter.com/p/head-of-claude-code-what-happens",
      "published": "2026-02-19T13:31:57+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "product",
        "growth",
        "leadership"
      ]
    },
    {
      "feed_id": "lenny",
      "feed_name": "Lenny's Newsletter",
      "title": "How to do AI analysis you can actually trust",
      "summary": "Four prompting techniques to prevent AI&#8217;s most common mistakes",
      "link": "https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually",
      "published": "2026-02-17T13:45:26+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "product",
        "growth",
        "leadership"
      ]
    },
    {
      "feed_id": "lenny",
      "feed_name": "Lenny's Newsletter",
      "title": "How to do AI analysis you can actually trust",
      "summary": "Four prompting techniques to prevent AI&#8217;s most common mistakes",
      "link": "https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually-db6",
      "published": "2026-02-17T13:02:46+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "product",
        "growth",
        "leadership"
      ]
    },
    {
      "feed_id": "lenny",
      "feed_name": "Lenny's Newsletter",
      "title": "üéôÔ∏è This week on How I AI: Opus vs. Codex showdown, and AI for accessibility",
      "summary": "Your weekly listens from How I AI, part of the Lenny's Podcast Network",
      "link": "https://www.lennysnewsletter.com/p/this-week-on-how-i-ai-opus-vs-codex",
      "published": "2026-02-16T16:02:43+00:00",
      "matched_keywords": [
        "ai"
      ],
      "relevance_score": 1,
      "feed_focus": [
        "product",
        "growth",
        "leadership"
      ]
    }
  ]
}