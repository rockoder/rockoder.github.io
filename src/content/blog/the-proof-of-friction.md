---
title: "The Proof of Friction: Why Trust Requires a Cost"
date: 2026-02-15
author: "Ganesh Pagade"
tags: ["ai", "trust", "information-theory", "media"]
description: "How the removal of production costs by generative models destroys the primary signal we verify digital reality."
draft: false
---

We often speak of trust as a moral qualityâ€”a commitment to truth or a reflection of character. But in the context of information systems, trust has historically been a byproduct of friction. We trusted a well-researched article or a detailed technical guide not just because we liked the author, but because the very existence of the work served as a "proof of work." The effort required to produce it was a signal that the information was likely worth the attention.

The core disruption of large language models is not that they hallucinate or make mistakes; it is that they have decoupled the signal of "high-quality presentation" from the "cost of production."

When it was difficult to produce a professional-looking website or a coherent multi-paragraph essay, the quality of the presentation acted as a reliable, if imperfect, filter. We used "vibe" as a proxy for effort, and effort as a proxy for truth. Today, this filter has collapsed. The cost of generating a plausible-sounding hit piece, a fake technical manual, or a fabricated quote is now effectively zero. This removes the "friction" that previously underpinned our trust in the public web. We are moving from an era where we looked for reasons to trust a source to one where there is an increasing tendency to look for reasons to distrust everything by default.

The risk for established institutions is that they are currently "spending" their legacy reputation. A reputable publication might use automated tools to increase volume, banking on the fact that readers still associate their masthead with the high-friction editorial processes of the past. But reputation is a lagging indicator. It is a memory of past friction. If an institution stops doing the work but continues to produce the signal, they are essentially liquidating their brand equity. The danger is not just that they produce "slop," but that they train the reader to ignore the masthead entirely. Once the link between effort and signal is broken, the brand becomes a hollow shell.

In response to this erosion, we see a logical retreat to environments where friction is still present. This takes several forms, from the reduction of audience size in local mesh networks to the use of digital signatures to tie work to a specific, persistent human identity. Others prioritize information that contains idiosyncratic, non-logical, or deeply specific human experiences that are difficult for current models to synthesize convincingly.

The consequence of this shift is that information will no longer be "free" in the sense of being easily verifiable. We are returning to a world where "truth" is once again tied to proximity and personal verification. The public web, once a commons of shared facts, is becoming a sea of competing simulations. In this environment, the most valuable asset is not the ability to produce information, but the ability to maintain the friction of verification. We may find that the only way to trust the internet again is to make it harder to participate in it.
